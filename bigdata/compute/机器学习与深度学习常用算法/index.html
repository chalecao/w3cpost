<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=preload as=font href=/fonts/vendor/jost/jost-v4-latin-regular.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=/fonts/vendor/jost/jost-v4-latin-500.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=/fonts/vendor/jost/jost-v4-latin-700.woff2 type=font/woff2 crossorigin><script>(()=>{var t=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,e=localStorage.getItem("theme");t&&e===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),t&&e==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script><link rel=stylesheet href=/main.f9552544b4ca62af741c0d24d283b4ddcfa2a026a871cff4112743eeb6c4950a530c923242d9d4d42e93635dd91ebd78601a145b8b205bb363d7065c1fa59ffe.css integrity="sha512-+VUlRLTKYq90HA0k0oO03c+ioCaocc/0ESdD7rbElQpTDJIyQtnU1C6TY13ZHr14YBoUW4sgW7Nj1wZcH6Wf/g==" crossorigin=anonymous><noscript><style>img.lazyload{display:none}</style></noscript><meta name=robots content="index, follow"><meta name=googlebot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=bingbot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><title>机器学习与深度学习常用算法 - 万维刀客「w3cdoc」</title><meta name=description content="要说最早，人工智能这个词其实最早来源于雨果的一本著作中，这是第一次出现这个词，而人工智能真正意义上来说，是在 _1956_年 _Dartmouth_学会上提出的，在学会上提出这个概念后，也就是从 _20_世纪 _50_年代中期到 _70_年代中期，众多学者以及研究人员对其展开了深刻的研究，这也是首次对人工智能这个概念进行了一个深入的研究，当然好景不长，我们当时时代的落后，科技的浅显，相关基础理论研究结果的匮乏，以及硬件与软件的落后使得人们对人工智能的这股热潮慢慢冷却。当时研究的最多的是模式识别，也是人工智能的代名词。
模式识别算法 # 模式识别是上世纪70-80年代的东西了，理论内容也比较纯粹了。模式识别主要可以做三件事情：分类、聚类和预测。其中聚类和分类是根据要解决的问题的类型是监督型数据还是非监督型数据来划分，预测主要是指根据设计的分类或者聚类算法来对下一步的结果做预测。
Classification (分类) # 分类是针对 Supervised Learning (监督学习)的处理方法。因为只有是有监督的（知道能分成几类），才可以用来做分类。
利用分类技术可以从数据集中提取描述数据类的一个函数或模型（也常称为分类器classifier），并把数据集中的每个对象归结到某个已知的对象类中。从机器学习的观点，分类技术是监督学习，即每个训练样本的数据对象已经有类标识，通过学习可以形成表达数据对象与类标识间对应的知识。所谓分类，简单来说，就是根据数据的特征或属性，划分到已有的类别中。
分类作为一种监督学习方法，要求必须事先明确知道各个类别的信息，并且断言所有待分类项都有一个类别与之对应。但是很多时候上述条件得不到满足，尤其是在处理海量数据的时候，如果通过预处理使得数据满足分类算法的要求，则代价非常大，这时候可以考虑使用聚类算法。
常用的分类算法包括 # 决策树分类法 基于规则的分类器 朴素的贝叶斯分类算法(native Bayesian classifier) 基于支持向量机(SVM)的分类器 神经网络法 k-最近邻法(k-nearest neighbor，kNN) 模糊分类法 举例 # 关于某个关键词的负面新闻检索。 已知类别，正面新闻还是负面新闻。所以是有监督。
全班同学高考主要都去了重点大学。 已知类别是重点大学还是普通大学，或者是211或者985, 分类是明确的，属于有监督。
Clustering(聚类) # 聚类是针对Unsupervised Learning (无监督学习)的，因为无监督的数据集合（不知道能分成几类），适合做聚类分析。
简单地说就是把相似的东西分到一组，聚类的时候，我们并不关心某一类是什么，我们的目标只是把相似的东西聚到一起。聚类分析就是将数据划分成有意义或有用的组（簇）。因此，一个聚类算法通常只需要知道如何计算相似度就可以开始工作了，因此 clustering 通常并不需要使用训练数据进行学习，即unsupervised learning (无监督学习)。聚类分析仅根据在数据中发现的描述对象及其关系的信息，将数据对象分组。其目标是，组内的对象相互之间是相似的，而不同组中的对象是不同的。
什么是一个好的聚类方法? # 一个好的聚类方法要能产生高质量的聚类结果——簇，这些簇要具备以下两个特点： 高的簇内相似性、低的簇间相似性
聚类结果的好坏取决于该聚类方法采用的相似性评估方法以及该方法的具体实现； 聚类方法的好坏还取决于该方法是否能发现某些还是所有的隐含模式；
不同的聚类类型 # 划分聚类（Partitional Clustering）：划分聚类简单地将数据对象集划分成不重叠的子集，使得每个数据对象恰在一个子集。 也正是根据所谓的“启发式算法”，形成了k-means算法及其变体包括k-medoids、k-modes、k-medians、kernel k-means等算法。 层次聚类（Hierarchical Clustering）：层次聚类是嵌套簇的集族，组织成一棵树。k-means算法。改进的算法有BIRCH（Balanced Iterative Reducing and Clustering Using Hierarchies）主要是在数据体量很大的时候使用，而且数据类型是numerical。 互斥聚类（Exclusive Clustering）：每个对象都指派到单个簇。 重叠的（Overlapping）或非互斥的（Non-exclusive）聚类：聚类用来反映一个对象.同时属于多个组（类）这一事实。例如：在大学里，一个人可能既是学生，又是雇员 模糊聚类（Fuzzy Clustering）：每个对象以一个0（绝对不属于）和1（绝对属于）之间的隶属权值属于每个簇。换言之，簇被视为模糊集。 FCM算法是一种以隶属度来确定每个数据点属于某个聚类程度的算法。该聚类算法是传统硬聚类算法的一种改进。 完全聚类（Complete Clustering）：完全聚类将每个对象指派到一个簇。 部分聚类（Partial Clustering)：部分聚类中数据集某些对象可能不属于明确定义的组。如：一些对象可能是离群点、噪声。 不同的簇类型 # 明显分离的（Well-Separated）：每个点到同簇中任一点的距离比到不同簇中所有点的距离更近。 基于原型的：每个对象到定义该簇的原型的距离比到其他簇的原型的距离更近。对于具有连续属性的数据，簇的原型通常是质心，即簇中所有点的平均值。当质心没有意义时，原型通常是中心点，即簇中最有代表性的点。 基于中心的（Center-Based）的簇：每个点到其簇中心的距离比到任何其他簇中心的距离更近。 ∙∙ 基于图的：如果数据用图表示，其中节点是对象，而边代表对象之间的联系。簇可以定义为连通分支（Connected Component）：互相连通但不与组外对象连通的对象组。 基于近邻的（Contiguity-Based）簇：其中两个对象是相连的，仅当它们的距离在指定的范围内。这意味着，每个对象到该簇某个对象的距离比到不同簇中任意点的距离更近。 ∙∙ 基于密度的（Density-Based）：簇是对象的稠密区域，被低密度的区域环绕。 ∙ 基于网络的方法（Grid-based methods）：这类方法的原理就是将数据空间划分为网格单元，将数据对象集映射到网格单元中，并计算每个单元的密度。根据预设的阈值判断每个网格单元是否为高密度单元，由邻近的稠密单元组形成”类“。STING（STatistical INformation Grid）算法、WAVE-CLUSTER算法和CLIQUE（CLustering In QUEst）是该类方法中的代表性算法。 (共同性质的)概念簇（Conceptual Clusters）：可以把簇定义为有某种共同性质的对象的集合。此情况下，聚类算法都需要非常具体的簇概念来成功检测这些簇，发现这些簇的过程称作概念聚类。DBSCAN（Density-Based Spatial Clustering of Applications with Noise）就是其中的典型."><link rel=canonical href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="机器学习与深度学习常用算法"><meta property="og:description" content="要说最早，人工智能这个词其实最早来源于雨果的一本著作中，这是第一次出现这个词，而人工智能真正意义上来说，是在 _1956_年 _Dartmouth_学会上提出的，在学会上提出这个概念后，也就是从 _20_世纪 _50_年代中期到 _70_年代中期，众多学者以及研究人员对其展开了深刻的研究，这也是首次对人工智能这个概念进行了一个深入的研究，当然好景不长，我们当时时代的落后，科技的浅显，相关基础理论研究结果的匮乏，以及硬件与软件的落后使得人们对人工智能的这股热潮慢慢冷却。当时研究的最多的是模式识别，也是人工智能的代名词。
模式识别算法 # 模式识别是上世纪70-80年代的东西了，理论内容也比较纯粹了。模式识别主要可以做三件事情：分类、聚类和预测。其中聚类和分类是根据要解决的问题的类型是监督型数据还是非监督型数据来划分，预测主要是指根据设计的分类或者聚类算法来对下一步的结果做预测。
Classification (分类) # 分类是针对 Supervised Learning (监督学习)的处理方法。因为只有是有监督的（知道能分成几类），才可以用来做分类。
利用分类技术可以从数据集中提取描述数据类的一个函数或模型（也常称为分类器classifier），并把数据集中的每个对象归结到某个已知的对象类中。从机器学习的观点，分类技术是监督学习，即每个训练样本的数据对象已经有类标识，通过学习可以形成表达数据对象与类标识间对应的知识。所谓分类，简单来说，就是根据数据的特征或属性，划分到已有的类别中。
分类作为一种监督学习方法，要求必须事先明确知道各个类别的信息，并且断言所有待分类项都有一个类别与之对应。但是很多时候上述条件得不到满足，尤其是在处理海量数据的时候，如果通过预处理使得数据满足分类算法的要求，则代价非常大，这时候可以考虑使用聚类算法。
常用的分类算法包括 # 决策树分类法 基于规则的分类器 朴素的贝叶斯分类算法(native Bayesian classifier) 基于支持向量机(SVM)的分类器 神经网络法 k-最近邻法(k-nearest neighbor，kNN) 模糊分类法 举例 # 关于某个关键词的负面新闻检索。 已知类别，正面新闻还是负面新闻。所以是有监督。
全班同学高考主要都去了重点大学。 已知类别是重点大学还是普通大学，或者是211或者985, 分类是明确的，属于有监督。
Clustering(聚类) # 聚类是针对Unsupervised Learning (无监督学习)的，因为无监督的数据集合（不知道能分成几类），适合做聚类分析。
简单地说就是把相似的东西分到一组，聚类的时候，我们并不关心某一类是什么，我们的目标只是把相似的东西聚到一起。聚类分析就是将数据划分成有意义或有用的组（簇）。因此，一个聚类算法通常只需要知道如何计算相似度就可以开始工作了，因此 clustering 通常并不需要使用训练数据进行学习，即unsupervised learning (无监督学习)。聚类分析仅根据在数据中发现的描述对象及其关系的信息，将数据对象分组。其目标是，组内的对象相互之间是相似的，而不同组中的对象是不同的。
什么是一个好的聚类方法? # 一个好的聚类方法要能产生高质量的聚类结果——簇，这些簇要具备以下两个特点： 高的簇内相似性、低的簇间相似性
聚类结果的好坏取决于该聚类方法采用的相似性评估方法以及该方法的具体实现； 聚类方法的好坏还取决于该方法是否能发现某些还是所有的隐含模式；
不同的聚类类型 # 划分聚类（Partitional Clustering）：划分聚类简单地将数据对象集划分成不重叠的子集，使得每个数据对象恰在一个子集。 也正是根据所谓的“启发式算法”，形成了k-means算法及其变体包括k-medoids、k-modes、k-medians、kernel k-means等算法。 层次聚类（Hierarchical Clustering）：层次聚类是嵌套簇的集族，组织成一棵树。k-means算法。改进的算法有BIRCH（Balanced Iterative Reducing and Clustering Using Hierarchies）主要是在数据体量很大的时候使用，而且数据类型是numerical。 互斥聚类（Exclusive Clustering）：每个对象都指派到单个簇。 重叠的（Overlapping）或非互斥的（Non-exclusive）聚类：聚类用来反映一个对象.同时属于多个组（类）这一事实。例如：在大学里，一个人可能既是学生，又是雇员 模糊聚类（Fuzzy Clustering）：每个对象以一个0（绝对不属于）和1（绝对属于）之间的隶属权值属于每个簇。换言之，簇被视为模糊集。 FCM算法是一种以隶属度来确定每个数据点属于某个聚类程度的算法。该聚类算法是传统硬聚类算法的一种改进。 完全聚类（Complete Clustering）：完全聚类将每个对象指派到一个簇。 部分聚类（Partial Clustering)：部分聚类中数据集某些对象可能不属于明确定义的组。如：一些对象可能是离群点、噪声。 不同的簇类型 # 明显分离的（Well-Separated）：每个点到同簇中任一点的距离比到不同簇中所有点的距离更近。 基于原型的：每个对象到定义该簇的原型的距离比到其他簇的原型的距离更近。对于具有连续属性的数据，簇的原型通常是质心，即簇中所有点的平均值。当质心没有意义时，原型通常是中心点，即簇中最有代表性的点。 基于中心的（Center-Based）的簇：每个点到其簇中心的距离比到任何其他簇中心的距离更近。 ∙∙ 基于图的：如果数据用图表示，其中节点是对象，而边代表对象之间的联系。簇可以定义为连通分支（Connected Component）：互相连通但不与组外对象连通的对象组。 基于近邻的（Contiguity-Based）簇：其中两个对象是相连的，仅当它们的距离在指定的范围内。这意味着，每个对象到该簇某个对象的距离比到不同簇中任意点的距离更近。 ∙∙ 基于密度的（Density-Based）：簇是对象的稠密区域，被低密度的区域环绕。 ∙ 基于网络的方法（Grid-based methods）：这类方法的原理就是将数据空间划分为网格单元，将数据对象集映射到网格单元中，并计算每个单元的密度。根据预设的阈值判断每个网格单元是否为高密度单元，由邻近的稠密单元组形成”类“。STING（STatistical INformation Grid）算法、WAVE-CLUSTER算法和CLIQUE（CLustering In QUEst）是该类方法中的代表性算法。 (共同性质的)概念簇（Conceptual Clusters）：可以把簇定义为有某种共同性质的对象的集合。此情况下，聚类算法都需要非常具体的簇概念来成功检测这些簇，发现这些簇的过程称作概念聚类。DBSCAN（Density-Based Spatial Clustering of Applications with Noise）就是其中的典型."><meta property="og:url" content="/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/"><meta property="og:site_name" content="万维刀客「w3cdoc」"><meta property="og:image" content="/doks.png"><meta property="og:image:alt" content="万维刀客「w3cdoc」"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content="@w3cdoc"><meta name=twitter:creator content="@chalecao"><meta name=twitter:title content="机器学习与深度学习常用算法"><meta name=twitter:description content><meta name=twitter:image content="/doks.png"><meta name=twitter:image:alt content="机器学习与深度学习常用算法"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"/#/schema/organization/1","name":"w3cdoc","url":"/","sameAs":["https://twitter.com/w3cdoc"],"logo":{"@type":"ImageObject","@id":"/#/schema/image/1","url":"/w3cdoc.png","width":512,"height":512,"caption":"w3cdoc"},"image":{"@id":"/#/schema/image/1"}},{"@type":"WebSite","@id":"/#/schema/website/1","url":"/","name":"万维刀客「w3cdoc」","description":"互联网同学互相帮助、学习成长的家园","publisher":{"@id":"/#/schema/organization/1"}},{"@type":"WebPage","@id":"/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/","url":"/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/","name":"机器学习与深度学习常用算法","description":"","isPartOf":{"@id":"/#/schema/website/1"},"about":{"@id":"/#/schema/organization/1"},"datePublished":"0001-01-01T00:00:00CET","dateModified":"0001-01-01T00:00:00CET","breadcrumb":{"@id":"/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/#/schema/breadcrumb/1"},"primaryImageOfPage":{"@id":"/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/#/schema/image/2"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/"]}]},{"@type":"BreadcrumbList","@id":"/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/#/schema/breadcrumb/1","name":"Breadcrumbs","itemListElement":[{"@type":"ListItem","position":1,"item":{"@type":"WebPage","@id":"/","url":"/","name":"Home"}},{"@type":"ListItem","position":2,"item":{"@id":"/bigdatacompute%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/"}}]},{"@context":"https://schema.org","@graph":[{"@type":"ImageObject","@id":"/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/#/schema/image/2","url":"/doks.png","contentUrl":"/doks.png","caption":"机器学习与深度学习常用算法"}]}]}</script><meta name=theme-color content="#fff"><link rel=icon href=/favicon.ico sizes=any><link rel=icon type=image/svg+xml href=/favicon.svg><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest crossorigin=use-credentials href=/site.webmanifest><script>"serviceWorker"in navigator&&navigator.serviceWorker.register("/sw.js",{scope:"/"}).then(function(e){console.log("Registration succeeded. Scope is "+e.scope)}).catch(function(e){console.log("Registration failed with "+e)})</script><script src=/js/vendor/autolog.js async></script></head><body class="bigdata single"><div class=sticky-top><div class=header-bar></div><header class="navbar navbar-expand-lg navbar-light doks-navbar"><nav class="container-xxl flex-wrap flex-lg-nowrap" aria-label="Main navigation"><a class="navbar-brand order-0" href=/ aria-label=万维刀客「w3cdoc」>万维刀客「w3cdoc」</a>
<button class="btn btn-menu order-2 d-block d-lg-none" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasDoks aria-controls=offcanvasDoks aria-label="Open main menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button><div class="offcanvas offcanvas-end border-0 py-lg-1" tabindex=-1 id=offcanvasDoks data-bs-backdrop=true aria-labelledby=offcanvasDoksLabel><div class="header-bar d-lg-none"></div><div class="offcanvas-header d-lg-none"><h2 class="h5 offcanvas-title ps-2" id=offcanvasDoksLabel><a class=text-dark href=/>万维刀客「w3cdoc」</a></h2><button type=button class="btn-close text-reset me-2" data-bs-dismiss=offcanvas aria-label="Close main menu"></button></div><div class="offcanvas-body p-4 p-lg-0"><ul class="nav flex-column flex-lg-row align-items-lg-center mt-2 mt-lg-0 ms-lg-2 me-lg-auto"><li class="nav-item dropdown"><a class="nav-link dropdown-toggle ps-0 py-1" href=# id=navbarDropdownMenuLink role=button data-bs-toggle=dropdown aria-expanded=false>初级入门
<span class=dropdown-caret><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-down"><polyline points="6 9 12 15 18 9"/></svg></span></a><ul class="dropdown-menu dropdown-menu-main shadow rounded border-0" aria-labelledby=navbarDropdownMenuLink><li><a class=dropdown-item href=/js/basic/javascript%E4%BB%8B%E7%BB%8D/>JS入门</a></li><li><a class=dropdown-item href=/git/basic/introduction/>Git入门</a></li></ul></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle ps-0 py-1" href=# id=navbarDropdownMenuLink role=button data-bs-toggle=dropdown aria-expanded=false>进阶学习
<span class=dropdown-caret><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-down"><polyline points="6 9 12 15 18 9"/></svg></span></a><ul class="dropdown-menu dropdown-menu-main shadow rounded border-0" aria-labelledby=navbarDropdownMenuLink><li><a class=dropdown-item href=/fed-regain/html/html%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2/>前端增长</a></li><li><a class=dropdown-item href=/webgl/base/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/>3D图形</a></li><li><a class=dropdown-item href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E4%BA%86%E8%A7%A3/>数据分析</a></li></ul></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/blog/>博客</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/course/>网课教程</a></li></ul><hr class="text-black-50 my-4 d-lg-none"><form class="doks-search position-relative flex-grow-1 ms-lg-auto me-lg-2"><input id=search class="form-control is-search" type=search placeholder="Search docs..." aria-label="Search docs..." autocomplete=off><div id=suggestions class="shadow bg-white rounded d-none"></div></form><hr class="text-black-50 my-4 d-lg-none"><ul class="nav flex-column flex-lg-row"></ul><hr class="text-black-50 my-4 d-lg-none"><button id=mode class="btn btn-link" type=button aria-label="Toggle user interface mode">
<span class=toggle-dark><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span><span class=toggle-light><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button></div></div></nav></header></div><div class=container-xxl><aside class=doks-sidebar><nav id=doks-docs-nav class="collapse d-lg-none" aria-label="Tertiary navigation"><ul class="list-unstyled collapsible-sidebar"><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-dd4e9c25c56177a32ad30dd10b4f68ff aria-expanded=true>
计算环境</button><div class="collapse show" id=section-dd4e9c25c56177a32ad30dd10b4f68ff><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E4%BA%86%E8%A7%A3/>机器学习基础了解</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%8B%E7%BB%8D/>机器学习与深度学习介绍</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/>机器学习基础数学知识</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E6%9C%AF%E8%AF%AD%E5%8F%8A%E5%90%AB%E4%B9%89/>机器学习常用术语及含义</a></li><li><a class="docs-link rounded active" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/>机器学习与深度学习常用算法</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%96%B9%E6%B3%95%E4%B8%8E%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B/>模型训练与损失和泛化能力</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%90%AD%E5%BB%BA%E6%9C%AC%E5%9C%B0python%E5%92%8Ctensorflow%E7%8E%AF%E5%A2%83/>搭建本地python和TensorFlow环境</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E5%9C%A8%E7%BA%BFjupyter%E7%8E%AF%E5%A2%83/>在线jupyter环境</a></li><li><a class="docs-link rounded" href=/bigdata/compute/python-%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/>python-编程基础知识</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-57a4cb7fa1cf829f30045bd59498a1bd aria-expanded=false>
计算框架</button><div class=collapse id=section-57a4cb7fa1cf829f30045bd59498a1bd><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/framework/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%BF%9B%E5%8C%96%E4%B9%8B%E8%B7%AF/>阿里巴巴的大数据进化之路</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%95%B0%E6%8D%AE%E5%BA%93mpp-mapreduce/>大数据数据库MPP-MapReduce</a></li><li><a class="docs-link rounded" href=/bigdata/framework/mpp%E6%9E%B6%E6%9E%84/>MPP架构</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B8%8E%E6%B5%81%E8%AE%A1%E7%AE%97%E4%BB%8B%E7%BB%8D/>大数据与流计算概览</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E6%B5%81%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8Eblink/>阿里巴巴流计算引擎Blink</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E6%B5%81%E8%AE%A1%E7%AE%97%E4%B9%8Bflink%E4%BB%8B%E7%BB%8D/>大数据之流计算之Flink介绍</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%95%B0%E6%8D%AE%E6%B9%96/>数据仓库数据湖</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93lake-house/>湖仓一体lake house</a></li><li><a class="docs-link rounded" href=/bigdata/framework/tensorflow-js%E7%AE%80%E5%8D%95%E6%A6%82%E5%BF%B5%E5%92%8C%E7%94%A8%E6%B3%95/>TensorFlow.js简单概念和用法</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-61bb1751fd355596e307767d1927c855 aria-expanded=false>
机器学习</button><div class=collapse id=section-61bb1751fd355596e307767d1927c855><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/ml/lstm%E4%BB%8B%E7%BB%8D/>LSTM介绍</a></li><li><a class="docs-link rounded" href=/bigdata/ml/lsm%E6%A0%91%E6%9C%89%E4%BB%80%E4%B9%88%E7%94%A8/>LSM树有什么用</a></li><li><a class="docs-link rounded" href=/bigdata/ml/kimball%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1/>KimBall维度建模</a></li><li><a class="docs-link rounded" href=/bigdata/ml/huffman%E6%A0%91%E5%92%8Chuffman%E7%BC%96%E7%A0%81/>Huffman树和Huffman编码</a></li><li><a class="docs-link rounded" href=/bigdata/ml/%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87%E4%B8%8E%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/>先验概率与后验概率、贝叶斯区别与联系</a></li><li><a class="docs-link rounded" href=/bigdata/ml/%E4%BB%8Eseq2seq%E5%88%B0attention%E6%A8%A1%E5%9E%8B%E5%88%B0self-attention1/>从Seq2seq到Attention模型到Self Attention（1）</a></li><li><a class="docs-link rounded" href=/bigdata/ml/%E4%BB%8Eseq2seq%E5%88%B0attention%E6%A8%A1%E5%9E%8B%E5%88%B0self-attention2/>从Seq2seq到Attention模型到Self Attention（2）</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-6450d84327e5a11bef853c4b9d557f42 aria-expanded=false>
数据分析</button><div class=collapse id=section-6450d84327e5a11bef853c4b9d557f42><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li class="my-1 ms-3"><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-3e958c6d36d4f85f47d730c55380b05f aria-expanded=false>
数据分析模型</button><div class=collapse id=section-3e958c6d36d4f85f47d730c55380b05f><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E4%BA%A4%E6%98%93%E6%A8%A1%E5%9E%8B/>交易模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E5%95%86%E4%B8%9A%E6%A8%A1%E5%BC%8F/>商业模式</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/rarra%E5%A2%9E%E9%95%BF%E6%A8%A1%E5%9E%8B/>RARRA增长模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/ttpprc%E5%95%86%E4%B8%9A%E6%A8%A1%E5%9E%8B/>TTPPRC商业模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E6%A0%87%E5%87%86%E7%B4%A2%E6%B4%9B%E6%A8%A1%E5%9E%8B/>标准索洛模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E9%9C%80%E6%B1%82%E4%B8%89%E8%A7%92%E6%A8%A1%E5%9E%8B/>需求三角模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E5%BF%83%E6%B5%81%E6%A8%A1%E5%9E%8B/>心流模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E4%B8%8A%E7%98%BE%E6%A8%A1%E5%9E%8B/>上瘾模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/mvp%E6%A8%A1%E5%9E%8B/>MVP模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/pmf%E6%A8%A1%E5%9E%8B/>PMF模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/35%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>35个数据分析模型</a></li></ul></div></li><li class="my-1 ms-3"><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-34afc8f397ba5a28887ab6dcab63b753 aria-expanded=false>
数据分析方法</button><div class=collapse id=section-34afc8f397ba5a28887ab6dcab63b753><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%82%B9%E5%87%BB%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>点击分析模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E8%A1%8C%E4%B8%BA%E4%BA%8B%E4%BB%B6%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>行为事件分析模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E6%BC%8F%E6%96%97%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>漏斗分析模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%94%A8%E6%88%B7%E5%88%86%E7%BE%A4%E7%94%BB%E5%83%8F/>用户分群画像</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/session%E4%BC%9A%E8%AF%9D%E5%88%86%E6%9E%90/>Session会话分析</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%A6%82%E4%BD%95%E5%81%9A%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90/>如何做用户行为分析</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%A6%8F%E6%A0%BC%E8%A1%8C%E4%B8%BA%E6%A8%A1%E5%9E%8B/>福格行为模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E9%BA%A6%E8%82%AF%E9%94%A1%E9%80%BB%E8%BE%91%E6%A0%91/>麦肯锡逻辑树</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E7%94%A8%E6%88%B7%E7%9A%84%E5%BF%83%E6%99%BA%E6%A8%A1%E5%9E%8B/>如何构建用户的心智模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%94%A8%E6%88%B7%E5%A2%9E%E9%95%BF%E4%B9%8Baarrr%E6%A8%A1%E5%9E%8B/>用户增长之AARRR模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%94%A8%E6%88%B7%E7%95%99%E5%AD%98%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>用户留存分析模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%9B%A0%E6%9E%9C%E5%85%B3%E7%B3%BB%E4%B9%8B%E6%A2%AF/>因果关系之梯</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%AE%A2%E6%88%B7%E4%BB%B7%E5%80%BC%E4%B8%BB%E5%BC%A0%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%BA%A7%E5%93%81%E4%BB%B7%E5%80%BC/>客户价值主张模型分析产品价值</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%B8%B8%E8%A7%81%E7%9A%84%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90%E6%B3%95/>常见的相关性分析法</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E8%B7%AF%E5%BE%84%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>用户行为路径分析模型</a></li></ul></div></li><li class="my-1 ms-3"><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-9a04dfa7d7b348c5eb595a08dac0f926 aria-expanded=false>
数据分析应用</button><div class=collapse id=section-9a04dfa7d7b348c5eb595a08dac0f926><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/analysis/action/%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C/>用户体验</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/action/%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C%E6%8C%87%E6%A0%87%E4%B9%8Bcsat-nps-ces/>用户体验指标之CSAT-NPS-CES</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/action/%E6%8F%90%E5%8D%87%E6%AF%9B%E5%88%A9%E7%8E%87%E7%9A%84%E4%B8%8D%E5%90%8C%E7%AD%96%E7%95%A5/>提升毛利率的不同策略</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/action/%E8%AE%A1%E5%88%86%E6%B3%95%E9%87%8F%E5%8C%96%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C/>计分法量化用户体验</a></li></ul></div></li></ul></div></li></ul></nav></aside></div><div class="wrap container-xxl" role=document><div class=content><div class="row flex-xl-nowrap"><div class="col-lg-5 col-xl-4 docs-sidebar d-none d-lg-block"><nav class=docs-links aria-label="Main navigation"><ul class="list-unstyled collapsible-sidebar"><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-dd4e9c25c56177a32ad30dd10b4f68ff aria-expanded=true>
计算环境</button><div class="collapse show" id=section-dd4e9c25c56177a32ad30dd10b4f68ff><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E4%BA%86%E8%A7%A3/>机器学习基础了解</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%8B%E7%BB%8D/>机器学习与深度学习介绍</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/>机器学习基础数学知识</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E6%9C%AF%E8%AF%AD%E5%8F%8A%E5%90%AB%E4%B9%89/>机器学习常用术语及含义</a></li><li><a class="docs-link rounded active" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/>机器学习与深度学习常用算法</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%96%B9%E6%B3%95%E4%B8%8E%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B/>模型训练与损失和泛化能力</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%90%AD%E5%BB%BA%E6%9C%AC%E5%9C%B0python%E5%92%8Ctensorflow%E7%8E%AF%E5%A2%83/>搭建本地python和TensorFlow环境</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E5%9C%A8%E7%BA%BFjupyter%E7%8E%AF%E5%A2%83/>在线jupyter环境</a></li><li><a class="docs-link rounded" href=/bigdata/compute/python-%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/>python-编程基础知识</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-57a4cb7fa1cf829f30045bd59498a1bd aria-expanded=false>
计算框架</button><div class=collapse id=section-57a4cb7fa1cf829f30045bd59498a1bd><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/framework/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%BF%9B%E5%8C%96%E4%B9%8B%E8%B7%AF/>阿里巴巴的大数据进化之路</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%95%B0%E6%8D%AE%E5%BA%93mpp-mapreduce/>大数据数据库MPP-MapReduce</a></li><li><a class="docs-link rounded" href=/bigdata/framework/mpp%E6%9E%B6%E6%9E%84/>MPP架构</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B8%8E%E6%B5%81%E8%AE%A1%E7%AE%97%E4%BB%8B%E7%BB%8D/>大数据与流计算概览</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E6%B5%81%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8Eblink/>阿里巴巴流计算引擎Blink</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E6%B5%81%E8%AE%A1%E7%AE%97%E4%B9%8Bflink%E4%BB%8B%E7%BB%8D/>大数据之流计算之Flink介绍</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%95%B0%E6%8D%AE%E6%B9%96/>数据仓库数据湖</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93lake-house/>湖仓一体lake house</a></li><li><a class="docs-link rounded" href=/bigdata/framework/tensorflow-js%E7%AE%80%E5%8D%95%E6%A6%82%E5%BF%B5%E5%92%8C%E7%94%A8%E6%B3%95/>TensorFlow.js简单概念和用法</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-61bb1751fd355596e307767d1927c855 aria-expanded=false>
机器学习</button><div class=collapse id=section-61bb1751fd355596e307767d1927c855><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/ml/lstm%E4%BB%8B%E7%BB%8D/>LSTM介绍</a></li><li><a class="docs-link rounded" href=/bigdata/ml/lsm%E6%A0%91%E6%9C%89%E4%BB%80%E4%B9%88%E7%94%A8/>LSM树有什么用</a></li><li><a class="docs-link rounded" href=/bigdata/ml/kimball%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1/>KimBall维度建模</a></li><li><a class="docs-link rounded" href=/bigdata/ml/huffman%E6%A0%91%E5%92%8Chuffman%E7%BC%96%E7%A0%81/>Huffman树和Huffman编码</a></li><li><a class="docs-link rounded" href=/bigdata/ml/%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87%E4%B8%8E%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/>先验概率与后验概率、贝叶斯区别与联系</a></li><li><a class="docs-link rounded" href=/bigdata/ml/%E4%BB%8Eseq2seq%E5%88%B0attention%E6%A8%A1%E5%9E%8B%E5%88%B0self-attention1/>从Seq2seq到Attention模型到Self Attention（1）</a></li><li><a class="docs-link rounded" href=/bigdata/ml/%E4%BB%8Eseq2seq%E5%88%B0attention%E6%A8%A1%E5%9E%8B%E5%88%B0self-attention2/>从Seq2seq到Attention模型到Self Attention（2）</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-6450d84327e5a11bef853c4b9d557f42 aria-expanded=false>
数据分析</button><div class=collapse id=section-6450d84327e5a11bef853c4b9d557f42><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li class="my-1 ms-3"><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-3e958c6d36d4f85f47d730c55380b05f aria-expanded=false>
数据分析模型</button><div class=collapse id=section-3e958c6d36d4f85f47d730c55380b05f><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E4%BA%A4%E6%98%93%E6%A8%A1%E5%9E%8B/>交易模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E5%95%86%E4%B8%9A%E6%A8%A1%E5%BC%8F/>商业模式</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/rarra%E5%A2%9E%E9%95%BF%E6%A8%A1%E5%9E%8B/>RARRA增长模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/ttpprc%E5%95%86%E4%B8%9A%E6%A8%A1%E5%9E%8B/>TTPPRC商业模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E6%A0%87%E5%87%86%E7%B4%A2%E6%B4%9B%E6%A8%A1%E5%9E%8B/>标准索洛模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E9%9C%80%E6%B1%82%E4%B8%89%E8%A7%92%E6%A8%A1%E5%9E%8B/>需求三角模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E5%BF%83%E6%B5%81%E6%A8%A1%E5%9E%8B/>心流模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E4%B8%8A%E7%98%BE%E6%A8%A1%E5%9E%8B/>上瘾模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/mvp%E6%A8%A1%E5%9E%8B/>MVP模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/pmf%E6%A8%A1%E5%9E%8B/>PMF模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/35%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>35个数据分析模型</a></li></ul></div></li><li class="my-1 ms-3"><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-34afc8f397ba5a28887ab6dcab63b753 aria-expanded=false>
数据分析方法</button><div class=collapse id=section-34afc8f397ba5a28887ab6dcab63b753><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%82%B9%E5%87%BB%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>点击分析模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E8%A1%8C%E4%B8%BA%E4%BA%8B%E4%BB%B6%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>行为事件分析模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E6%BC%8F%E6%96%97%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>漏斗分析模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%94%A8%E6%88%B7%E5%88%86%E7%BE%A4%E7%94%BB%E5%83%8F/>用户分群画像</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/session%E4%BC%9A%E8%AF%9D%E5%88%86%E6%9E%90/>Session会话分析</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%A6%82%E4%BD%95%E5%81%9A%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90/>如何做用户行为分析</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%A6%8F%E6%A0%BC%E8%A1%8C%E4%B8%BA%E6%A8%A1%E5%9E%8B/>福格行为模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E9%BA%A6%E8%82%AF%E9%94%A1%E9%80%BB%E8%BE%91%E6%A0%91/>麦肯锡逻辑树</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E7%94%A8%E6%88%B7%E7%9A%84%E5%BF%83%E6%99%BA%E6%A8%A1%E5%9E%8B/>如何构建用户的心智模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%94%A8%E6%88%B7%E5%A2%9E%E9%95%BF%E4%B9%8Baarrr%E6%A8%A1%E5%9E%8B/>用户增长之AARRR模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%94%A8%E6%88%B7%E7%95%99%E5%AD%98%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>用户留存分析模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%9B%A0%E6%9E%9C%E5%85%B3%E7%B3%BB%E4%B9%8B%E6%A2%AF/>因果关系之梯</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%AE%A2%E6%88%B7%E4%BB%B7%E5%80%BC%E4%B8%BB%E5%BC%A0%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%BA%A7%E5%93%81%E4%BB%B7%E5%80%BC/>客户价值主张模型分析产品价值</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%B8%B8%E8%A7%81%E7%9A%84%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90%E6%B3%95/>常见的相关性分析法</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E8%B7%AF%E5%BE%84%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>用户行为路径分析模型</a></li></ul></div></li><li class="my-1 ms-3"><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-9a04dfa7d7b348c5eb595a08dac0f926 aria-expanded=false>
数据分析应用</button><div class=collapse id=section-9a04dfa7d7b348c5eb595a08dac0f926><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/analysis/action/%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C/>用户体验</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/action/%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C%E6%8C%87%E6%A0%87%E4%B9%8Bcsat-nps-ces/>用户体验指标之CSAT-NPS-CES</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/action/%E6%8F%90%E5%8D%87%E6%AF%9B%E5%88%A9%E7%8E%87%E7%9A%84%E4%B8%8D%E5%90%8C%E7%AD%96%E7%95%A5/>提升毛利率的不同策略</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/action/%E8%AE%A1%E5%88%86%E6%B3%95%E9%87%8F%E5%8C%96%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C/>计分法量化用户体验</a></li></ul></div></li></ul></div></li></ul></nav></div><nav class="docs-toc d-none d-xl-block col-xl-3" aria-label="Secondary navigation"><div class=d-xl-none><button class="btn btn-outline-primary btn-sm doks-toc-toggle collapsed" type=button data-bs-toggle=collapse data-bs-target=#onThisPage aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle On this page navigation">
<span>On this page</span>
<span><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></span></button>
<button class="btn btn-outline-primary btn-sm doks-toc-toggle collapsed" type=button data-bs-toggle=collapse data-bs-target=#doks-docs-nav aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle On this page navigation">
<span>Book Menu</span>
<span><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></span></button><div class=collapse id=onThisPage><div class="card card-body mt-3 py-1"><div class=page-links><nav id=TableOfContents><ul><li><a href=#classification-分类>Classification (分类)</a><ul><li><a href=#常用的分类算法包括>常用的分类算法包括</a></li><li><a href=#举例>举例</a></li></ul></li><li><a href=#clustering聚类>Clustering(聚类)</a><ul><li><a href=#什么是一个好的聚类方法>什么是一个好的聚类方法?</a></li><li><a href=#不同的聚类类型>不同的聚类类型</a></li><li><a href=#不同的簇类型>不同的簇类型</a></li><li><a href=#举例-1>举例</a></li></ul></li></ul><ul><li><a href=#4大主要学习方式>4大主要学习方式</a></li><li><a href=#常用算法>常用算法</a><ul><li><a href=#举例-2>举例</a></li></ul></li></ul><ul><li><a href=#常用算法-1>常用算法</a></li></ul></nav></div></div></div></div><div class="page-links d-none d-xl-block"><h3>On this page</h3><nav id=TableOfContents><ul><li><a href=#classification-分类>Classification (分类)</a><ul><li><a href=#常用的分类算法包括>常用的分类算法包括</a></li><li><a href=#举例>举例</a></li></ul></li><li><a href=#clustering聚类>Clustering(聚类)</a><ul><li><a href=#什么是一个好的聚类方法>什么是一个好的聚类方法?</a></li><li><a href=#不同的聚类类型>不同的聚类类型</a></li><li><a href=#不同的簇类型>不同的簇类型</a></li><li><a href=#举例-1>举例</a></li></ul></li></ul><ul><li><a href=#4大主要学习方式>4大主要学习方式</a></li><li><a href=#常用算法>常用算法</a><ul><li><a href=#举例-2>举例</a></li></ul></li></ul><ul><li><a href=#常用算法-1>常用算法</a></li></ul></nav></div></nav><main class="docs-content col-lg-11 col-xl-9 mx-xl-auto"><h1>机器学习与深度学习常用算法</h1><p class=lead></p><nav class=d-xl-none aria-label="Quaternary navigation"><div class=d-xl-none><button class="btn btn-outline-primary btn-sm doks-toc-toggle collapsed" type=button data-bs-toggle=collapse data-bs-target=#onThisPage aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle On this page navigation">
<span>On this page</span>
<span><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></span></button>
<button class="btn btn-outline-primary btn-sm doks-toc-toggle collapsed" type=button data-bs-toggle=collapse data-bs-target=#doks-docs-nav aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle On this page navigation">
<span>Book Menu</span>
<span><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></span></button><div class=collapse id=onThisPage><div class="card card-body mt-3 py-1"><div class=page-links><nav id=TableOfContents><ul><li><a href=#classification-分类>Classification (分类)</a><ul><li><a href=#常用的分类算法包括>常用的分类算法包括</a></li><li><a href=#举例>举例</a></li></ul></li><li><a href=#clustering聚类>Clustering(聚类)</a><ul><li><a href=#什么是一个好的聚类方法>什么是一个好的聚类方法?</a></li><li><a href=#不同的聚类类型>不同的聚类类型</a></li><li><a href=#不同的簇类型>不同的簇类型</a></li><li><a href=#举例-1>举例</a></li></ul></li></ul><ul><li><a href=#4大主要学习方式>4大主要学习方式</a></li><li><a href=#常用算法>常用算法</a><ul><li><a href=#举例-2>举例</a></li></ul></li></ul><ul><li><a href=#常用算法-1>常用算法</a></li></ul></nav></div></div></div></div><div class="page-links d-none d-xl-block"><h3>On this page</h3><nav id=TableOfContents><ul><li><a href=#classification-分类>Classification (分类)</a><ul><li><a href=#常用的分类算法包括>常用的分类算法包括</a></li><li><a href=#举例>举例</a></li></ul></li><li><a href=#clustering聚类>Clustering(聚类)</a><ul><li><a href=#什么是一个好的聚类方法>什么是一个好的聚类方法?</a></li><li><a href=#不同的聚类类型>不同的聚类类型</a></li><li><a href=#不同的簇类型>不同的簇类型</a></li><li><a href=#举例-1>举例</a></li></ul></li></ul><ul><li><a href=#4大主要学习方式>4大主要学习方式</a></li><li><a href=#常用算法>常用算法</a><ul><li><a href=#举例-2>举例</a></li></ul></li></ul><ul><li><a href=#常用算法-1>常用算法</a></li></ul></nav></div></nav><p>要说最早，人工智能这个词其实最早来源于雨果的一本著作中，这是第一次出现这个词，而人工智能真正意义上来说，是在 _1956_年 _Dartmouth_学会上提出的，在学会上提出这个概念后，也就是从 _20_世纪 _50_年代中期到 _70_年代中期，众多学者以及研究人员对其展开了深刻的研究，这也是首次对人工智能这个概念进行了一个深入的研究，当然好景不长，<a href=https://www.w3cdoc.com>我们</a>当时时代的落后，科技的浅显，相关基础理论研究结果的匮乏，以及硬件与软件的落后使得人们对人工智能的这股热潮慢慢冷却。当时研究的最多的是模式识别，也是人工智能的代名词。</p><h1 id=模式识别算法>模式识别算法 <a href=#%e6%a8%a1%e5%bc%8f%e8%af%86%e5%88%ab%e7%ae%97%e6%b3%95 class=anchor aria-hidden=true>#</a></h1><p>模式识别是上世纪70-80年代的东西了，理论内容也比较纯粹了。模式识别主要可以做三件事情：分类、聚类和预测。其中聚类和分类是根据要解决的问题的类型是监督型数据还是非监督型数据来划分，预测主要是指根据设计的分类或者聚类算法来对下一步的结果做预测。</p><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-21-43-17.png></p><h2 id=classification-分类>Classification (分类) <a href=#classification-%e5%88%86%e7%b1%bb class=anchor aria-hidden=true>#</a></h2><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-21-43-28.png></p><p>分类是针对 Supervised Learning (监督学习)的处理方法。因为只有是有监督的（知道能分成几类），才可以用来做分类。</p><p>利用分类技术可以从数据集中提取描述数据类的一个函数或模型（也常称为分类器classifier），并把数据集中的每个对象归结到某个已知的对象类中。从机器学习的观点，分类技术是监督学习，即每个训练样本的数据对象已经有类标识，通过学习可以形成表达数据对象与类标识间对应的知识。所谓分类，简单来说，就是根据数据的特征或属性，划分到已有的类别中。</p><p>分类作为一种监督学习方法，要求必须事先明确知道各个类别的信息，并且断言所有待分类项都有一个类别与之对应。但是很多时候上述条件得不到满足，尤其是在处理海量数据的时候，如果通过预处理使得数据满足分类算法的要求，则代价非常大，这时候可以考虑使用聚类算法。</p><h3 id=常用的分类算法包括>常用的分类算法包括 <a href=#%e5%b8%b8%e7%94%a8%e7%9a%84%e5%88%86%e7%b1%bb%e7%ae%97%e6%b3%95%e5%8c%85%e6%8b%ac class=anchor aria-hidden=true>#</a></h3><ul><li>决策树分类法</li><li>基于规则的分类器</li><li>朴素的贝叶斯分类算法(native Bayesian classifier)</li><li>基于支持向量机(SVM)的分类器</li><li>神经网络法</li><li>k-最近邻法(k-nearest neighbor，kNN)</li><li>模糊分类法</li></ul><h3 id=举例>举例 <a href=#%e4%b8%be%e4%be%8b class=anchor aria-hidden=true>#</a></h3><ol><li>关于某个关键词的负面新闻检索。</li></ol><p>已知类别，正面新闻还是负面新闻。所以是有监督。</p><ol><li>全班同学高考主要都去了重点大学。</li></ol><p>已知类别是重点大学还是普通大学，或者是211或者985, 分类是明确的，属于有监督。</p><h2 id=clustering聚类>Clustering(聚类) <a href=#clustering%e8%81%9a%e7%b1%bb class=anchor aria-hidden=true>#</a></h2><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-21-43-43.png></p><p>聚类是针对Unsupervised Learning (无监督学习)的，因为无监督的数据集合（不知道能分成几类），适合做聚类分析。</p><p>简单地说就是把相似的东西分到一组，聚类的时候，<a href=https://www.w3cdoc.com>我们</a>并不关心某一类是什么，<a href=https://www.w3cdoc.com>我们</a>的目标只是把相似的东西聚到一起。聚类分析就是将数据划分成有意义或有用的组（簇）。因此，一个聚类算法通常只需要知道如何计算相似度就可以开始工作了，因此 clustering 通常并不需要使用训练数据进行学习，即unsupervised learning (无监督学习)。聚类分析仅根据在数据中发现的描述对象及其关系的信息，将数据对象分组。其目标是，组内的对象相互之间是相似的，而不同组中的对象是不同的。</p><h3 id=什么是一个好的聚类方法>什么是一个好的聚类方法? <a href=#%e4%bb%80%e4%b9%88%e6%98%af%e4%b8%80%e4%b8%aa%e5%a5%bd%e7%9a%84%e8%81%9a%e7%b1%bb%e6%96%b9%e6%b3%95 class=anchor aria-hidden=true>#</a></h3><p>一个好的聚类方法要能产生高质量的聚类结果——簇，这些簇要具备以下两个特点： 高的簇内相似性、低的簇间相似性</p><p>聚类结果的好坏取决于该聚类方法采用的相似性评估方法以及该方法的具体实现； 聚类方法的好坏还取决于该方法是否能发现某些还是所有的隐含模式；</p><h3 id=不同的聚类类型>不同的聚类类型 <a href=#%e4%b8%8d%e5%90%8c%e7%9a%84%e8%81%9a%e7%b1%bb%e7%b1%bb%e5%9e%8b class=anchor aria-hidden=true>#</a></h3><ul><li>划分聚类（Partitional Clustering）：划分聚类简单地将数据对象集划分成不重叠的子集，使得每个数据对象恰在一个子集。 也正是根据所谓的“启发式算法”，形成了k-means算法及其变体包括k-medoids、k-modes、k-medians、kernel k-means等算法。</li><li>层次聚类（Hierarchical Clustering）：层次聚类是嵌套簇的集族，组织成一棵树。k-means算法。改进的算法有BIRCH（Balanced Iterative Reducing and Clustering Using Hierarchies）主要是在数据体量很大的时候使用，而且数据类型是numerical。</li><li>互斥聚类（Exclusive Clustering）：每个对象都指派到单个簇。</li><li>重叠的（Overlapping）或非互斥的（Non-exclusive）聚类：聚类用来反映一个对象.同时属于多个组（类）这一事实。例如：在大学里，一个人可能既是学生，又是雇员</li><li>模糊聚类（Fuzzy Clustering）：每个对象以一个0（绝对不属于）和1（绝对属于）之间的隶属权值属于每个簇。换言之，簇被视为模糊集。 FCM算法是一种以隶属度来确定每个数据点属于某个聚类程度的算法。该聚类算法是传统硬聚类算法的一种改进。</li><li>完全聚类（Complete Clustering）：完全聚类将每个对象指派到一个簇。</li><li>部分聚类（Partial Clustering)：部分聚类中数据集某些对象可能不属于明确定义的组。如：一些对象可能是离群点、噪声。</li></ul><h3 id=不同的簇类型>不同的簇类型 <a href=#%e4%b8%8d%e5%90%8c%e7%9a%84%e7%b0%87%e7%b1%bb%e5%9e%8b class=anchor aria-hidden=true>#</a></h3><ul><li>明显分离的（Well-Separated）：每个点到同簇中任一点的距离比到不同簇中所有点的距离更近。</li><li>基于原型的：每个对象到定义该簇的原型的距离比到其他簇的原型的距离更近。对于具有连续属性的数据，簇的原型通常是质心，即簇中所有点的平均值。当质心没有意义时，原型通常是中心点，即簇中最有代表性的点。</li><li>基于中心的（Center-Based）的簇：每个点到其簇中心的距离比到任何其他簇中心的距离更近。 ∙∙</li><li>基于图的：如果数据用图表示，其中节点是对象，而边代表对象之间的联系。簇可以定义为连通分支（Connected Component）：互相连通但不与组外对象连通的对象组。</li><li>基于近邻的（Contiguity-Based）簇：其中两个对象是相连的，仅当它们的距离在指定的范围内。这意味着，每个对象到该簇某个对象的距离比到不同簇中任意点的距离更近。 ∙∙</li><li>基于密度的（Density-Based）：簇是对象的稠密区域，被低密度的区域环绕。 ∙</li><li>基于网络的方法（Grid-based methods）：这类方法的原理就是将数据空间划分为网格单元，将数据对象集映射到网格单元中，并计算每个单元的密度。根据预设的阈值判断每个网格单元是否为高密度单元，由邻近的稠密单元组形成”类“。STING（STatistical INformation Grid）算法、WAVE-CLUSTER算法和CLIQUE（CLustering In QUEst）是该类方法中的代表性算法。</li><li>(共同性质的)概念簇（Conceptual Clusters）：可以把簇定义为有某种共同性质的对象的集合。此情况下，聚类算法都需要非常具体的簇概念来成功检测这些簇，发现这些簇的过程称作概念聚类。DBSCAN（Density-Based Spatial Clustering of Applications with Noise）就是其中的典型.</li></ul><h3 id=举例-1>举例 <a href=#%e4%b8%be%e4%be%8b-1 class=anchor aria-hidden=true>#</a></h3><ul><li>自动新闻分组</li><li>自动邮件归类</li></ul><h1 id=机器学习算法>机器学习算法 <a href=#%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e7%ae%97%e6%b3%95 class=anchor aria-hidden=true>#</a></h1><p>机器学习的算法很多。很多时候困惑人们都是，很多算法是一类算法，而有些算法又是从其他算法中延伸出来的。这里，<a href=https://www.w3cdoc.com>我们</a>从两个方面来给<a href=https://www.w3cdoc.com>大家</a>介绍：</p><ul><li>学习的方式</li><li>算法的分类</li></ul><p>先看下这个机器学习图谱：</p><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-21-45-07.png></p><h2 id=4大主要学习方式>4大主要学习方式 <a href=#4%e5%a4%a7%e4%b8%bb%e8%a6%81%e5%ad%a6%e4%b9%a0%e6%96%b9%e5%bc%8f class=anchor aria-hidden=true>#</a></h2><ul><li>监督式学习</li></ul><p>在监督式学习下，输入数据被称为“训练数据”，每组训练数据有一个明确的标识或结果，如对防垃圾邮件系统中“垃圾邮件”“非垃圾邮件”，对手写数字识别中的“1“，”2“，”3“，”4“等。在建立预测模型的时候，监督式学习建立一个学习过程，将预测结果与“训练数据”的实际结果进行比较，不断的调整预测模型，直到模型的预测结果达到一个预期的准确率。监督式学习的常见应用场景如分类问题和回归问题。常见算法有逻辑回归（Logistic Regression）和反向传递神经网络（Back Propagation Neural Network）。</p><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-21-45-17.png></p><ul><li>半监督式学习</li></ul><p>在此学习方式下，输入数据部分被标识，部分没有被标识，这种学习模型可以用来进行预测，但是模型首先需要学习数据的内在结构以便合理的组织数据来进行预测。应用场景包括分类和回归，算法包括一些对常用监督式学习算法的延伸，这些算法首先试图对未标识数据进行建模，在此基础上再对标识的数据进行预测。如图论推理算法（Graph Inference）或者拉普拉斯支持向量机（Laplacian SVM.）等。</p><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-21-45-28.png></p><ul><li>非监督式学习</li></ul><p>在非监督式学习中，数据并不被特别标识，学习模型是为了推断出数据的一些内在结构。常见的应用场景包括关联规则的学习以及聚类等。常见算法包括Apriori算法以及k-Means算法。</p><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-21-45-42.png></p><ul><li>强化学习</li></ul><p>在这种学习模式下，输入数据作为对模型的反馈，不像监督模型那样，输入数据仅仅是作为一个检查模型对错的方式，在强化学习下，输入数据直接反馈到模型，模型必须对此立刻作出调整。常见的应用场景包括动态系统以及机器人控制等。常见算法包括Q-Learning以及时间差学习（Temporal difference learning）。</p><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-21-45-51.png></p><h2 id=常用算法>常用算法 <a href=#%e5%b8%b8%e7%94%a8%e7%ae%97%e6%b3%95 class=anchor aria-hidden=true>#</a></h2><p>根据算法的功能和形式的类似性，<a href=https://www.w3cdoc.com>我们</a>可以把算法分类，比如说基于树的算法，基于神经网络的算法等等。当然，机器学习的范围非常庞大，有些算法很难明确归类到某一类。</p><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-21-46-03.png></p><h3 id=举例-2>举例 <a href=#%e4%b8%be%e4%be%8b-2 class=anchor aria-hidden=true>#</a></h3><ol><li>根据卫星云图，预测明天下雨的概率。</li></ol><p>很多例子，这里就不一一列举了。因为机器学习主要是强调学习的方法和过程，然后是使用的算法模型。</p><h1 id=深度学习>深度学习 <a href=#%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0 class=anchor aria-hidden=true>#</a></h1><p>深度学习强调的是你使用的模型（例如深度卷积多层神经网络），模型中的参数通过从数据中学习获得。然而，深度学习也带来了一些其他需要考虑的问题。因为你面对的是一个高维的模型（即庞大的网络），所以你需要大量的数据（大数据）和强大的运算能力（图形处理器，GPU）才能优化这个模型。卷积被广泛用于深度学习（尤其是计算机视觉应用中），而且它的架构往往都是非浅层的。</p><h2 id=常用算法-1>常用算法 <a href=#%e5%b8%b8%e7%94%a8%e7%ae%97%e6%b3%95-1 class=anchor aria-hidden=true>#</a></h2><ul><li>卷积网络（Convolutional Network）</li><li>循环神经网络（LSTM）（Recurrent Neural Network (LSTM)）</li><li>受限玻尔兹曼机（Restricted Boltzmann Machine）</li><li>深度信念网络（Deep Belief Network）</li><li>作为RBM堆叠的深度自编码器（Deep Autoencoder as stack of RBMs）</li><li>去噪自编码器（Denoising Autoencoder）</li><li>堆叠的去噪自编码器（Stacked Denoising Autoencoder）</li><li>作为去噪自编码器堆叠的深度自编码器（Deep Autoencoder as stack of Denoising Autoencoders）</li><li>多层感知器（MultiLayer Perceptron）</li><li>Logistic 回归</li></ul><h1 id=参考>参考 <a href=#%e5%8f%82%e8%80%83 class=anchor aria-hidden=true>#</a></h1><ul><li>https://blog.csdn.net/abc200941410128/article/details/78541273</li><li>https://cloud.tencent.com/developer/article/1029070</li><li>https://www.tinymind.cn/articles/632?from=articles_commend</li><li>https://blog.csdn.net/abc200941410128/article/details/79269386</li><li>https://www.jiqizhixin.com/articles/2016-10-11-4</li></ul><div class="page-footer-meta d-flex flex-column flex-md-row justify-content-between"></div><div class="docs-navigation d-flex justify-content-between"><a href=/bigdata/analysis/action/%E6%8F%90%E5%8D%87%E6%AF%9B%E5%88%A9%E7%8E%87%E7%9A%84%E4%B8%8D%E5%90%8C%E7%AD%96%E7%95%A5/><div class="card my-1"><div class="card-body py-2">&larr; 提升毛利率的不同策略</div></div></a><a class=ms-auto href=/bigdata/analysis/method/%E6%BC%8F%E6%96%97%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/><div class="card my-1"><div class="card-body py-2">漏斗分析模型 &rarr;</div></div></a></div></main></div></div></div><footer class="footer text-muted"><div class=container-xxl><div class=row><div class="col-lg-8 order-last order-lg-first"><ul class=list-inline><li class=list-inline-item>Copyright © 2022-Present 浙ICP备18052292号-3</li></ul></div><div class="col-lg-8 order-first order-lg-last text-lg-end"><ul class=list-inline></ul></div></div></div></footer><script src=/js/bootstrap.min.1117772738b0b01188ff56b000f75758d3ca75fab55d0d7cf813282148e4840455e1fc0a8f1c2951391282de6e64bed66b885160643382a58f67db6d110e9feb.js integrity="sha512-ERd3JziwsBGI/1awAPdXWNPKdfq1XQ18+BMoIUjkhARV4fwKjxwpUTkSgt5uZL7Wa4hRYGQzgqWPZ9ttEQ6f6w==" crossorigin=anonymous defer></script>
<script src=/js/highlight.min.35e8488ad0bca08539c53f48a94a3c02f90c10ddc1ecba4a7fd7ec827cef556dec98a33813e3681b33a5750eefd53e65ab606d30febc27e411c293f2290f96a5.js integrity="sha512-NehIitC8oIU5xT9IqUo8AvkMEN3B7LpKf9fsgnzvVW3smKM4E+NoGzOldQ7v1T5lq2BtMP68J+QRwpPyKQ+WpQ==" crossorigin=anonymous defer></script>
<script src=/main.min.5874482df6978e314928bf4ce1c634b6464aa5445dd098e344aa61159e2b10139d82662edd47e835a3ea422c24214134f15eded85f28e55774a70f9c4919b2b3.js integrity="sha512-WHRILfaXjjFJKL9M4cY0tkZKpURd0JjjRKphFZ4rEBOdgmYu3UfoNaPqQiwkIUE08V7e2F8o5Vd0pw+cSRmysw==" crossorigin=anonymous defer></script>
<script src=/index.min.4ae26272486ea46c5bb0bed7a0b434a91b05e8182cfb839a405dd4e647b05ce5d76d401a5103d822d3b1589fc56335cd372b712d97085b8d89aebf244b1b5501.js integrity="sha512-SuJickhupGxbsL7XoLQ0qRsF6Bgs+4OaQF3U5kewXOXXbUAaUQPYItOxWJ/FYzXNNytxLZcIW42Jrr8kSxtVAQ==" crossorigin=anonymous defer></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML" async></script>
<script type="text/x-mathjax-config;executed=true">
  window.MathJax.Hub.Config({
      showProcessingMessages: false, //关闭js加载过程信息
      messageStyle: "none", //不显示信息
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
          inlineMath: [["$", "$"], ["\\(", "\\)"]], //行内公式选择符
          displayMath: [["$$", "$$"], ["\\[", "\\]"]], //段内公式选择符
          skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //避开某些标签
      },
      "HTML-CSS": {
          availableFonts: ["STIX", "TeX"], //可选字体
          showMathMenu: false //关闭右击菜单显示
      }
  });
  //下面第三个参数可以不写，默认对整个html内的latex进行翻译
  window.MathJax.Hub.Queue(["Typeset", MathJax.Hub, document.getElementsByClassName("ck-content")]);
</script></body></html>