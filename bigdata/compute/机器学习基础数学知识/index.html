<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=preload as=font href=/fonts/vendor/jost/jost-v4-latin-regular.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=/fonts/vendor/jost/jost-v4-latin-500.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=/fonts/vendor/jost/jost-v4-latin-700.woff2 type=font/woff2 crossorigin><script>(()=>{var t=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,e=localStorage.getItem("theme");t&&e===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),t&&e==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script><link rel=stylesheet href=/main.f9552544b4ca62af741c0d24d283b4ddcfa2a026a871cff4112743eeb6c4950a530c923242d9d4d42e93635dd91ebd78601a145b8b205bb363d7065c1fa59ffe.css integrity="sha512-+VUlRLTKYq90HA0k0oO03c+ioCaocc/0ESdD7rbElQpTDJIyQtnU1C6TY13ZHr14YBoUW4sgW7Nj1wZcH6Wf/g==" crossorigin=anonymous><noscript><style>img.lazyload{display:none}</style></noscript><meta name=robots content="index, follow"><meta name=googlebot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=bingbot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><title>机器学习基础数学知识 - 万维刀客「w3cdoc」</title><meta name=description content="机器学习速成课程中介绍并应用了以下概念和工具。有关详情，请参阅链接的资源。
高等数学 # 变量、系数和函数 大家上高中都学过变量的概率，比如未知数[latex]x[/latex]是一个变量，系数比如[latex]2x[/latex]，其中数字2就是变量的系数，函数就是表达两个变量关系的等式。
线性方程式，例如: [latex]y = b + w_1x_1 + w_2x_2[/latex] 如上面的线性方程的例子，这是个二元一次方程，包含两个自变量x，一个因变量y，表达了这三个变量之间的关系。
对数和对数方程式，例如: [latex]y = ln1+ e^z 如果 [latex]b^y = x[/latex] 那么 [latex]log_b(x) = y[/latex]，是不是很好理解。[latex]log_e(x) = lnx， ln是一种简写形式。
S 型函数又叫sigmod函数，在神经网络中作为激活函数。 Sigmoid函数又分为Log-Sigmoid函数和Tan-Sigmoid函数。
Log-Sigmoid函数: [latex]\sigma(z) = \frac{1}{1+e^{-z}}[/latex]，图形如下：
Tan-Sigmoid函数: [latex]\sigma(z) = \frac{2}{1+e^{-2z}} - 1[/latex]
线性代数 # 张量和张量阶数 # 现代的数学观点定义：张量是多重线性函数， 输入r个向量，输出1个数，r称作张量的阶数。多重线性是指张量对于每个参数都是线性的,对于单个参数就是： ,其中u,v 是任意向量，c 是任意数。
TensorFlow用张量这种数据结构来表示所有的数据.你可以把一个张量想象成一个n维的数组或列表.一个张量有一个静态类型和动态类型的维数.张量可以在图中的节点之间流通.在TensorFlow系统中，张量的维数来被描述为阶.但是张量的阶和矩阵的阶并不是同一个概念.张量的阶（有时是关于如顺序或度数或者是n维）是张量维数的一个数量描述.比如，下面的张量（使用Python中list定义的）就是2阶.
t = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] 你可以认为一个二阶张量就是我们平常所说的矩阵，一阶张量可以认为是一个向量.对于一个二阶张量你可以用语句t[i, j]来访问其中的任何元素.而对于三阶张量你可以用’t[i, j, k]’来访问其中的任何元素.
张量是所有深度学习框架中最核心的组件，因为后续的所有运算和优化算法都是基于张量进行的。几何代数中定义的张量是基于向量和矩阵的推广，通俗一点理解的话，我们可以将标量视为零阶张量，矢量视为一阶张量，那么矩阵就是二阶张量。
阶,数学实例,Python例子"><link rel=canonical href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="机器学习基础数学知识"><meta property="og:description" content="机器学习速成课程中介绍并应用了以下概念和工具。有关详情，请参阅链接的资源。
高等数学 # 变量、系数和函数 大家上高中都学过变量的概率，比如未知数[latex]x[/latex]是一个变量，系数比如[latex]2x[/latex]，其中数字2就是变量的系数，函数就是表达两个变量关系的等式。
线性方程式，例如: [latex]y = b + w_1x_1 + w_2x_2[/latex] 如上面的线性方程的例子，这是个二元一次方程，包含两个自变量x，一个因变量y，表达了这三个变量之间的关系。
对数和对数方程式，例如: [latex]y = ln1+ e^z 如果 [latex]b^y = x[/latex] 那么 [latex]log_b(x) = y[/latex]，是不是很好理解。[latex]log_e(x) = lnx， ln是一种简写形式。
S 型函数又叫sigmod函数，在神经网络中作为激活函数。 Sigmoid函数又分为Log-Sigmoid函数和Tan-Sigmoid函数。
Log-Sigmoid函数: [latex]\sigma(z) = \frac{1}{1+e^{-z}}[/latex]，图形如下：
Tan-Sigmoid函数: [latex]\sigma(z) = \frac{2}{1+e^{-2z}} - 1[/latex]
线性代数 # 张量和张量阶数 # 现代的数学观点定义：张量是多重线性函数， 输入r个向量，输出1个数，r称作张量的阶数。多重线性是指张量对于每个参数都是线性的,对于单个参数就是： ,其中u,v 是任意向量，c 是任意数。
TensorFlow用张量这种数据结构来表示所有的数据.你可以把一个张量想象成一个n维的数组或列表.一个张量有一个静态类型和动态类型的维数.张量可以在图中的节点之间流通.在TensorFlow系统中，张量的维数来被描述为阶.但是张量的阶和矩阵的阶并不是同一个概念.张量的阶（有时是关于如顺序或度数或者是n维）是张量维数的一个数量描述.比如，下面的张量（使用Python中list定义的）就是2阶.
t = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] 你可以认为一个二阶张量就是我们平常所说的矩阵，一阶张量可以认为是一个向量.对于一个二阶张量你可以用语句t[i, j]来访问其中的任何元素.而对于三阶张量你可以用’t[i, j, k]’来访问其中的任何元素.
张量是所有深度学习框架中最核心的组件，因为后续的所有运算和优化算法都是基于张量进行的。几何代数中定义的张量是基于向量和矩阵的推广，通俗一点理解的话，我们可以将标量视为零阶张量，矢量视为一阶张量，那么矩阵就是二阶张量。
阶,数学实例,Python例子"><meta property="og:url" content="/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/"><meta property="og:site_name" content="万维刀客「w3cdoc」"><meta property="og:image" content="/doks.png"><meta property="og:image:alt" content="万维刀客「w3cdoc」"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content="@w3cdoc"><meta name=twitter:creator content="@chalecao"><meta name=twitter:title content="机器学习基础数学知识"><meta name=twitter:description content><meta name=twitter:image content="/doks.png"><meta name=twitter:image:alt content="机器学习基础数学知识"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"/#/schema/organization/1","name":"w3cdoc","url":"/","sameAs":["https://twitter.com/w3cdoc"],"logo":{"@type":"ImageObject","@id":"/#/schema/image/1","url":"/w3cdoc.png","width":512,"height":512,"caption":"w3cdoc"},"image":{"@id":"/#/schema/image/1"}},{"@type":"WebSite","@id":"/#/schema/website/1","url":"/","name":"万维刀客「w3cdoc」","description":"互联网同学互相帮助、学习成长的家园","publisher":{"@id":"/#/schema/organization/1"}},{"@type":"WebPage","@id":"/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/","url":"/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/","name":"机器学习基础数学知识","description":"","isPartOf":{"@id":"/#/schema/website/1"},"about":{"@id":"/#/schema/organization/1"},"datePublished":"0001-01-01T00:00:00CET","dateModified":"0001-01-01T00:00:00CET","breadcrumb":{"@id":"/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/#/schema/breadcrumb/1"},"primaryImageOfPage":{"@id":"/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/#/schema/image/2"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/"]}]},{"@type":"BreadcrumbList","@id":"/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/#/schema/breadcrumb/1","name":"Breadcrumbs","itemListElement":[{"@type":"ListItem","position":1,"item":{"@type":"WebPage","@id":"/","url":"/","name":"Home"}},{"@type":"ListItem","position":2,"item":{"@id":"/bigdatacompute%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/"}}]},{"@context":"https://schema.org","@graph":[{"@type":"ImageObject","@id":"/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/#/schema/image/2","url":"/doks.png","contentUrl":"/doks.png","caption":"机器学习基础数学知识"}]}]}</script><meta name=theme-color content="#fff"><link rel=icon href=/favicon.ico sizes=any><link rel=icon type=image/svg+xml href=/favicon.svg><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest crossorigin=use-credentials href=/site.webmanifest><script>"serviceWorker"in navigator&&navigator.serviceWorker.register("/sw.js",{scope:"/"}).then(function(e){console.log("Registration succeeded. Scope is "+e.scope)}).catch(function(e){console.log("Registration failed with "+e)})</script><script src=/js/vendor/autolog.js async></script></head><body class="bigdata single"><div class=sticky-top><div class=header-bar></div><header class="navbar navbar-expand-lg navbar-light doks-navbar"><nav class="container-xxl flex-wrap flex-lg-nowrap" aria-label="Main navigation"><a class="navbar-brand order-0" href=/ aria-label=万维刀客「w3cdoc」>万维刀客「w3cdoc」</a>
<button class="btn btn-menu order-2 d-block d-lg-none" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasDoks aria-controls=offcanvasDoks aria-label="Open main menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button><div class="offcanvas offcanvas-end border-0 py-lg-1" tabindex=-1 id=offcanvasDoks data-bs-backdrop=true aria-labelledby=offcanvasDoksLabel><div class="header-bar d-lg-none"></div><div class="offcanvas-header d-lg-none"><h2 class="h5 offcanvas-title ps-2" id=offcanvasDoksLabel><a class=text-dark href=/>万维刀客「w3cdoc」</a></h2><button type=button class="btn-close text-reset me-2" data-bs-dismiss=offcanvas aria-label="Close main menu"></button></div><div class="offcanvas-body p-4 p-lg-0"><ul class="nav flex-column flex-lg-row align-items-lg-center mt-2 mt-lg-0 ms-lg-2 me-lg-auto"><li class="nav-item dropdown"><a class="nav-link dropdown-toggle ps-0 py-1" href=# id=navbarDropdownMenuLink role=button data-bs-toggle=dropdown aria-expanded=false>初级入门
<span class=dropdown-caret><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-down"><polyline points="6 9 12 15 18 9"/></svg></span></a><ul class="dropdown-menu dropdown-menu-main shadow rounded border-0" aria-labelledby=navbarDropdownMenuLink><li><a class=dropdown-item href=/js/basic/javascript%E4%BB%8B%E7%BB%8D/>JS入门</a></li><li><a class=dropdown-item href=/git/basic/introduction/>Git入门</a></li></ul></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle ps-0 py-1" href=# id=navbarDropdownMenuLink role=button data-bs-toggle=dropdown aria-expanded=false>进阶学习
<span class=dropdown-caret><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-down"><polyline points="6 9 12 15 18 9"/></svg></span></a><ul class="dropdown-menu dropdown-menu-main shadow rounded border-0" aria-labelledby=navbarDropdownMenuLink><li><a class=dropdown-item href=/fed-regain/html/html%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2/>前端增长</a></li><li><a class=dropdown-item href=/webgl/base/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/>3D图形</a></li><li><a class=dropdown-item href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E4%BA%86%E8%A7%A3/>数据分析</a></li></ul></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/blog/>博客</a></li><li class=nav-item><a class="nav-link ps-0 py-1" href=/course/>网课教程</a></li></ul><hr class="text-black-50 my-4 d-lg-none"><form class="doks-search position-relative flex-grow-1 ms-lg-auto me-lg-2"><input id=search class="form-control is-search" type=search placeholder="Search docs..." aria-label="Search docs..." autocomplete=off><div id=suggestions class="shadow bg-white rounded d-none"></div></form><hr class="text-black-50 my-4 d-lg-none"><ul class="nav flex-column flex-lg-row"></ul><hr class="text-black-50 my-4 d-lg-none"><button id=mode class="btn btn-link" type=button aria-label="Toggle user interface mode">
<span class=toggle-dark><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span><span class=toggle-light><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button></div></div></nav></header></div><div class=container-xxl><aside class=doks-sidebar><nav id=doks-docs-nav class="collapse d-lg-none" aria-label="Tertiary navigation"><ul class="list-unstyled collapsible-sidebar"><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-dd4e9c25c56177a32ad30dd10b4f68ff aria-expanded=true>
计算环境</button><div class="collapse show" id=section-dd4e9c25c56177a32ad30dd10b4f68ff><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E4%BA%86%E8%A7%A3/>机器学习基础了解</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%8B%E7%BB%8D/>机器学习与深度学习介绍</a></li><li><a class="docs-link rounded active" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/>机器学习基础数学知识</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E6%9C%AF%E8%AF%AD%E5%8F%8A%E5%90%AB%E4%B9%89/>机器学习常用术语及含义</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/>机器学习与深度学习常用算法</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%96%B9%E6%B3%95%E4%B8%8E%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B/>模型训练与损失和泛化能力</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%90%AD%E5%BB%BA%E6%9C%AC%E5%9C%B0python%E5%92%8Ctensorflow%E7%8E%AF%E5%A2%83/>搭建本地python和TensorFlow环境</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E5%9C%A8%E7%BA%BFjupyter%E7%8E%AF%E5%A2%83/>在线jupyter环境</a></li><li><a class="docs-link rounded" href=/bigdata/compute/python-%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/>python-编程基础知识</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-57a4cb7fa1cf829f30045bd59498a1bd aria-expanded=false>
计算框架</button><div class=collapse id=section-57a4cb7fa1cf829f30045bd59498a1bd><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/framework/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%BF%9B%E5%8C%96%E4%B9%8B%E8%B7%AF/>阿里巴巴的大数据进化之路</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%95%B0%E6%8D%AE%E5%BA%93mpp-mapreduce/>大数据数据库MPP-MapReduce</a></li><li><a class="docs-link rounded" href=/bigdata/framework/mpp%E6%9E%B6%E6%9E%84/>MPP架构</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B8%8E%E6%B5%81%E8%AE%A1%E7%AE%97%E4%BB%8B%E7%BB%8D/>大数据与流计算概览</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E6%B5%81%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8Eblink/>阿里巴巴流计算引擎Blink</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E6%B5%81%E8%AE%A1%E7%AE%97%E4%B9%8Bflink%E4%BB%8B%E7%BB%8D/>大数据之流计算之Flink介绍</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%95%B0%E6%8D%AE%E6%B9%96/>数据仓库数据湖</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93lake-house/>湖仓一体lake house</a></li><li><a class="docs-link rounded" href=/bigdata/framework/tensorflow-js%E7%AE%80%E5%8D%95%E6%A6%82%E5%BF%B5%E5%92%8C%E7%94%A8%E6%B3%95/>TensorFlow.js简单概念和用法</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-61bb1751fd355596e307767d1927c855 aria-expanded=false>
机器学习</button><div class=collapse id=section-61bb1751fd355596e307767d1927c855><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/ml/lstm%E4%BB%8B%E7%BB%8D/>LSTM介绍</a></li><li><a class="docs-link rounded" href=/bigdata/ml/lsm%E6%A0%91%E6%9C%89%E4%BB%80%E4%B9%88%E7%94%A8/>LSM树有什么用</a></li><li><a class="docs-link rounded" href=/bigdata/ml/kimball%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1/>KimBall维度建模</a></li><li><a class="docs-link rounded" href=/bigdata/ml/huffman%E6%A0%91%E5%92%8Chuffman%E7%BC%96%E7%A0%81/>Huffman树和Huffman编码</a></li><li><a class="docs-link rounded" href=/bigdata/ml/%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87%E4%B8%8E%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/>先验概率与后验概率、贝叶斯区别与联系</a></li><li><a class="docs-link rounded" href=/bigdata/ml/%E4%BB%8Eseq2seq%E5%88%B0attention%E6%A8%A1%E5%9E%8B%E5%88%B0self-attention1/>从Seq2seq到Attention模型到Self Attention（1）</a></li><li><a class="docs-link rounded" href=/bigdata/ml/%E4%BB%8Eseq2seq%E5%88%B0attention%E6%A8%A1%E5%9E%8B%E5%88%B0self-attention2/>从Seq2seq到Attention模型到Self Attention（2）</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-6450d84327e5a11bef853c4b9d557f42 aria-expanded=false>
数据分析</button><div class=collapse id=section-6450d84327e5a11bef853c4b9d557f42><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li class="my-1 ms-3"><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-3e958c6d36d4f85f47d730c55380b05f aria-expanded=false>
数据分析模型</button><div class=collapse id=section-3e958c6d36d4f85f47d730c55380b05f><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E4%BA%A4%E6%98%93%E6%A8%A1%E5%9E%8B/>交易模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E5%95%86%E4%B8%9A%E6%A8%A1%E5%BC%8F/>商业模式</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/rarra%E5%A2%9E%E9%95%BF%E6%A8%A1%E5%9E%8B/>RARRA增长模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/ttpprc%E5%95%86%E4%B8%9A%E6%A8%A1%E5%9E%8B/>TTPPRC商业模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E6%A0%87%E5%87%86%E7%B4%A2%E6%B4%9B%E6%A8%A1%E5%9E%8B/>标准索洛模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E9%9C%80%E6%B1%82%E4%B8%89%E8%A7%92%E6%A8%A1%E5%9E%8B/>需求三角模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E5%BF%83%E6%B5%81%E6%A8%A1%E5%9E%8B/>心流模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E4%B8%8A%E7%98%BE%E6%A8%A1%E5%9E%8B/>上瘾模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/mvp%E6%A8%A1%E5%9E%8B/>MVP模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/pmf%E6%A8%A1%E5%9E%8B/>PMF模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/35%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>35个数据分析模型</a></li></ul></div></li><li class="my-1 ms-3"><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-34afc8f397ba5a28887ab6dcab63b753 aria-expanded=false>
数据分析方法</button><div class=collapse id=section-34afc8f397ba5a28887ab6dcab63b753><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%82%B9%E5%87%BB%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>点击分析模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E8%A1%8C%E4%B8%BA%E4%BA%8B%E4%BB%B6%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>行为事件分析模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E6%BC%8F%E6%96%97%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>漏斗分析模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%94%A8%E6%88%B7%E5%88%86%E7%BE%A4%E7%94%BB%E5%83%8F/>用户分群画像</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/session%E4%BC%9A%E8%AF%9D%E5%88%86%E6%9E%90/>Session会话分析</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%A6%82%E4%BD%95%E5%81%9A%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90/>如何做用户行为分析</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%A6%8F%E6%A0%BC%E8%A1%8C%E4%B8%BA%E6%A8%A1%E5%9E%8B/>福格行为模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E9%BA%A6%E8%82%AF%E9%94%A1%E9%80%BB%E8%BE%91%E6%A0%91/>麦肯锡逻辑树</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E7%94%A8%E6%88%B7%E7%9A%84%E5%BF%83%E6%99%BA%E6%A8%A1%E5%9E%8B/>如何构建用户的心智模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%94%A8%E6%88%B7%E5%A2%9E%E9%95%BF%E4%B9%8Baarrr%E6%A8%A1%E5%9E%8B/>用户增长之AARRR模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%94%A8%E6%88%B7%E7%95%99%E5%AD%98%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>用户留存分析模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%9B%A0%E6%9E%9C%E5%85%B3%E7%B3%BB%E4%B9%8B%E6%A2%AF/>因果关系之梯</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%AE%A2%E6%88%B7%E4%BB%B7%E5%80%BC%E4%B8%BB%E5%BC%A0%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%BA%A7%E5%93%81%E4%BB%B7%E5%80%BC/>客户价值主张模型分析产品价值</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%B8%B8%E8%A7%81%E7%9A%84%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90%E6%B3%95/>常见的相关性分析法</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E8%B7%AF%E5%BE%84%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>用户行为路径分析模型</a></li></ul></div></li><li class="my-1 ms-3"><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-9a04dfa7d7b348c5eb595a08dac0f926 aria-expanded=false>
数据分析应用</button><div class=collapse id=section-9a04dfa7d7b348c5eb595a08dac0f926><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/analysis/action/%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C/>用户体验</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/action/%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C%E6%8C%87%E6%A0%87%E4%B9%8Bcsat-nps-ces/>用户体验指标之CSAT-NPS-CES</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/action/%E6%8F%90%E5%8D%87%E6%AF%9B%E5%88%A9%E7%8E%87%E7%9A%84%E4%B8%8D%E5%90%8C%E7%AD%96%E7%95%A5/>提升毛利率的不同策略</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/action/%E8%AE%A1%E5%88%86%E6%B3%95%E9%87%8F%E5%8C%96%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C/>计分法量化用户体验</a></li></ul></div></li></ul></div></li></ul></nav></aside></div><div class="wrap container-xxl" role=document><div class=content><div class="row flex-xl-nowrap"><div class="col-lg-5 col-xl-4 docs-sidebar d-none d-lg-block"><nav class=docs-links aria-label="Main navigation"><ul class="list-unstyled collapsible-sidebar"><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-dd4e9c25c56177a32ad30dd10b4f68ff aria-expanded=true>
计算环境</button><div class="collapse show" id=section-dd4e9c25c56177a32ad30dd10b4f68ff><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E4%BA%86%E8%A7%A3/>机器学习基础了解</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%8B%E7%BB%8D/>机器学习与深度学习介绍</a></li><li><a class="docs-link rounded active" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/>机器学习基础数学知识</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E6%9C%AF%E8%AF%AD%E5%8F%8A%E5%90%AB%E4%B9%89/>机器学习常用术语及含义</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/>机器学习与深度学习常用算法</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%96%B9%E6%B3%95%E4%B8%8E%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B/>模型训练与损失和泛化能力</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E6%90%AD%E5%BB%BA%E6%9C%AC%E5%9C%B0python%E5%92%8Ctensorflow%E7%8E%AF%E5%A2%83/>搭建本地python和TensorFlow环境</a></li><li><a class="docs-link rounded" href=/bigdata/compute/%E5%9C%A8%E7%BA%BFjupyter%E7%8E%AF%E5%A2%83/>在线jupyter环境</a></li><li><a class="docs-link rounded" href=/bigdata/compute/python-%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/>python-编程基础知识</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-57a4cb7fa1cf829f30045bd59498a1bd aria-expanded=false>
计算框架</button><div class=collapse id=section-57a4cb7fa1cf829f30045bd59498a1bd><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/framework/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%BF%9B%E5%8C%96%E4%B9%8B%E8%B7%AF/>阿里巴巴的大数据进化之路</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%95%B0%E6%8D%AE%E5%BA%93mpp-mapreduce/>大数据数据库MPP-MapReduce</a></li><li><a class="docs-link rounded" href=/bigdata/framework/mpp%E6%9E%B6%E6%9E%84/>MPP架构</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B8%8E%E6%B5%81%E8%AE%A1%E7%AE%97%E4%BB%8B%E7%BB%8D/>大数据与流计算概览</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E6%B5%81%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8Eblink/>阿里巴巴流计算引擎Blink</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E6%B5%81%E8%AE%A1%E7%AE%97%E4%B9%8Bflink%E4%BB%8B%E7%BB%8D/>大数据之流计算之Flink介绍</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%95%B0%E6%8D%AE%E6%B9%96/>数据仓库数据湖</a></li><li><a class="docs-link rounded" href=/bigdata/framework/%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93lake-house/>湖仓一体lake house</a></li><li><a class="docs-link rounded" href=/bigdata/framework/tensorflow-js%E7%AE%80%E5%8D%95%E6%A6%82%E5%BF%B5%E5%92%8C%E7%94%A8%E6%B3%95/>TensorFlow.js简单概念和用法</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-61bb1751fd355596e307767d1927c855 aria-expanded=false>
机器学习</button><div class=collapse id=section-61bb1751fd355596e307767d1927c855><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/ml/lstm%E4%BB%8B%E7%BB%8D/>LSTM介绍</a></li><li><a class="docs-link rounded" href=/bigdata/ml/lsm%E6%A0%91%E6%9C%89%E4%BB%80%E4%B9%88%E7%94%A8/>LSM树有什么用</a></li><li><a class="docs-link rounded" href=/bigdata/ml/kimball%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1/>KimBall维度建模</a></li><li><a class="docs-link rounded" href=/bigdata/ml/huffman%E6%A0%91%E5%92%8Chuffman%E7%BC%96%E7%A0%81/>Huffman树和Huffman编码</a></li><li><a class="docs-link rounded" href=/bigdata/ml/%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87%E4%B8%8E%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB/>先验概率与后验概率、贝叶斯区别与联系</a></li><li><a class="docs-link rounded" href=/bigdata/ml/%E4%BB%8Eseq2seq%E5%88%B0attention%E6%A8%A1%E5%9E%8B%E5%88%B0self-attention1/>从Seq2seq到Attention模型到Self Attention（1）</a></li><li><a class="docs-link rounded" href=/bigdata/ml/%E4%BB%8Eseq2seq%E5%88%B0attention%E6%A8%A1%E5%9E%8B%E5%88%B0self-attention2/>从Seq2seq到Attention模型到Self Attention（2）</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-6450d84327e5a11bef853c4b9d557f42 aria-expanded=false>
数据分析</button><div class=collapse id=section-6450d84327e5a11bef853c4b9d557f42><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li class="my-1 ms-3"><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-3e958c6d36d4f85f47d730c55380b05f aria-expanded=false>
数据分析模型</button><div class=collapse id=section-3e958c6d36d4f85f47d730c55380b05f><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E4%BA%A4%E6%98%93%E6%A8%A1%E5%9E%8B/>交易模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E5%95%86%E4%B8%9A%E6%A8%A1%E5%BC%8F/>商业模式</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/rarra%E5%A2%9E%E9%95%BF%E6%A8%A1%E5%9E%8B/>RARRA增长模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/ttpprc%E5%95%86%E4%B8%9A%E6%A8%A1%E5%9E%8B/>TTPPRC商业模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E6%A0%87%E5%87%86%E7%B4%A2%E6%B4%9B%E6%A8%A1%E5%9E%8B/>标准索洛模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E9%9C%80%E6%B1%82%E4%B8%89%E8%A7%92%E6%A8%A1%E5%9E%8B/>需求三角模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E5%BF%83%E6%B5%81%E6%A8%A1%E5%9E%8B/>心流模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/%E4%B8%8A%E7%98%BE%E6%A8%A1%E5%9E%8B/>上瘾模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/mvp%E6%A8%A1%E5%9E%8B/>MVP模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/pmf%E6%A8%A1%E5%9E%8B/>PMF模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/model/35%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>35个数据分析模型</a></li></ul></div></li><li class="my-1 ms-3"><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-34afc8f397ba5a28887ab6dcab63b753 aria-expanded=false>
数据分析方法</button><div class=collapse id=section-34afc8f397ba5a28887ab6dcab63b753><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%82%B9%E5%87%BB%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>点击分析模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E8%A1%8C%E4%B8%BA%E4%BA%8B%E4%BB%B6%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>行为事件分析模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E6%BC%8F%E6%96%97%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>漏斗分析模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%94%A8%E6%88%B7%E5%88%86%E7%BE%A4%E7%94%BB%E5%83%8F/>用户分群画像</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/session%E4%BC%9A%E8%AF%9D%E5%88%86%E6%9E%90/>Session会话分析</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%A6%82%E4%BD%95%E5%81%9A%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90/>如何做用户行为分析</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%A6%8F%E6%A0%BC%E8%A1%8C%E4%B8%BA%E6%A8%A1%E5%9E%8B/>福格行为模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E9%BA%A6%E8%82%AF%E9%94%A1%E9%80%BB%E8%BE%91%E6%A0%91/>麦肯锡逻辑树</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E7%94%A8%E6%88%B7%E7%9A%84%E5%BF%83%E6%99%BA%E6%A8%A1%E5%9E%8B/>如何构建用户的心智模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%94%A8%E6%88%B7%E5%A2%9E%E9%95%BF%E4%B9%8Baarrr%E6%A8%A1%E5%9E%8B/>用户增长之AARRR模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%94%A8%E6%88%B7%E7%95%99%E5%AD%98%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>用户留存分析模型</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%9B%A0%E6%9E%9C%E5%85%B3%E7%B3%BB%E4%B9%8B%E6%A2%AF/>因果关系之梯</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%AE%A2%E6%88%B7%E4%BB%B7%E5%80%BC%E4%B8%BB%E5%BC%A0%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E4%BA%A7%E5%93%81%E4%BB%B7%E5%80%BC/>客户价值主张模型分析产品价值</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E5%B8%B8%E8%A7%81%E7%9A%84%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%90%E6%B3%95/>常见的相关性分析法</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/method/%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E8%B7%AF%E5%BE%84%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/>用户行为路径分析模型</a></li></ul></div></li><li class="my-1 ms-3"><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-9a04dfa7d7b348c5eb595a08dac0f926 aria-expanded=false>
数据分析应用</button><div class=collapse id=section-9a04dfa7d7b348c5eb595a08dac0f926><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/bigdata/analysis/action/%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C/>用户体验</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/action/%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C%E6%8C%87%E6%A0%87%E4%B9%8Bcsat-nps-ces/>用户体验指标之CSAT-NPS-CES</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/action/%E6%8F%90%E5%8D%87%E6%AF%9B%E5%88%A9%E7%8E%87%E7%9A%84%E4%B8%8D%E5%90%8C%E7%AD%96%E7%95%A5/>提升毛利率的不同策略</a></li><li><a class="docs-link rounded" href=/bigdata/analysis/action/%E8%AE%A1%E5%88%86%E6%B3%95%E9%87%8F%E5%8C%96%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C/>计分法量化用户体验</a></li></ul></div></li></ul></div></li></ul></nav></div><nav class="docs-toc d-none d-xl-block col-xl-3" aria-label="Secondary navigation"><div class=d-xl-none><button class="btn btn-outline-primary btn-sm doks-toc-toggle collapsed" type=button data-bs-toggle=collapse data-bs-target=#onThisPage aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle On this page navigation">
<span>On this page</span>
<span><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></span></button>
<button class="btn btn-outline-primary btn-sm doks-toc-toggle collapsed" type=button data-bs-toggle=collapse data-bs-target=#doks-docs-nav aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle On this page navigation">
<span>Book Menu</span>
<span><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></span></button><div class=collapse id=onThisPage><div class="card card-body mt-3 py-1"><div class=page-links><nav id=TableOfContents><ul><li><a href=#高等数学>高等数学</a></li><li><a href=#线性代数>线性代数</a><ul><li><a href=#张量和张量阶数>张量和张量阶数</a></li><li><a href=#矩阵乘法>矩阵乘法</a></li></ul></li><li><a href=#三角学>三角学</a></li><li><a href=#统计信息>统计信息</a></li><li><a href=#微积分可选适合高级主题>微积分（可选，适合高级主题）</a></li><li><a href=#参考资料>参考资料</a></li></ul></nav></div></div></div></div><div class="page-links d-none d-xl-block"><h3>On this page</h3><nav id=TableOfContents><ul><li><a href=#高等数学>高等数学</a></li><li><a href=#线性代数>线性代数</a><ul><li><a href=#张量和张量阶数>张量和张量阶数</a></li><li><a href=#矩阵乘法>矩阵乘法</a></li></ul></li><li><a href=#三角学>三角学</a></li><li><a href=#统计信息>统计信息</a></li><li><a href=#微积分可选适合高级主题>微积分（可选，适合高级主题）</a></li><li><a href=#参考资料>参考资料</a></li></ul></nav></div></nav><main class="docs-content col-lg-11 col-xl-9 mx-xl-auto"><h1>机器学习基础数学知识</h1><p class=lead></p><nav class=d-xl-none aria-label="Quaternary navigation"><div class=d-xl-none><button class="btn btn-outline-primary btn-sm doks-toc-toggle collapsed" type=button data-bs-toggle=collapse data-bs-target=#onThisPage aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle On this page navigation">
<span>On this page</span>
<span><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></span></button>
<button class="btn btn-outline-primary btn-sm doks-toc-toggle collapsed" type=button data-bs-toggle=collapse data-bs-target=#doks-docs-nav aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle On this page navigation">
<span>Book Menu</span>
<span><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></span></button><div class=collapse id=onThisPage><div class="card card-body mt-3 py-1"><div class=page-links><nav id=TableOfContents><ul><li><a href=#高等数学>高等数学</a></li><li><a href=#线性代数>线性代数</a><ul><li><a href=#张量和张量阶数>张量和张量阶数</a></li><li><a href=#矩阵乘法>矩阵乘法</a></li></ul></li><li><a href=#三角学>三角学</a></li><li><a href=#统计信息>统计信息</a></li><li><a href=#微积分可选适合高级主题>微积分（可选，适合高级主题）</a></li><li><a href=#参考资料>参考资料</a></li></ul></nav></div></div></div></div><div class="page-links d-none d-xl-block"><h3>On this page</h3><nav id=TableOfContents><ul><li><a href=#高等数学>高等数学</a></li><li><a href=#线性代数>线性代数</a><ul><li><a href=#张量和张量阶数>张量和张量阶数</a></li><li><a href=#矩阵乘法>矩阵乘法</a></li></ul></li><li><a href=#三角学>三角学</a></li><li><a href=#统计信息>统计信息</a></li><li><a href=#微积分可选适合高级主题>微积分（可选，适合高级主题）</a></li><li><a href=#参考资料>参考资料</a></li></ul></nav></div></nav><p>机器学习速成课程中介绍并应用了以下概念和工具。有关详情，请参阅链接的资源。</p><h2 id=高等数学>高等数学 <a href=#%e9%ab%98%e7%ad%89%e6%95%b0%e5%ad%a6 class=anchor aria-hidden=true>#</a></h2><ul><li>变量、系数和函数</li></ul><p><a href=https://www.w3cdoc.com>大家</a>上高中都学过变量的概率，比如未知数[latex]x[/latex]是一个变量，系数比如[latex]2x[/latex]，其中数字2就是变量的系数，函数就是表达两个变量关系的等式。</p><ul><li>线性方程式，例如: [latex]y = b + w_1x_1 + w_2x_2[/latex]</li></ul><p>如上面的线性方程的例子，这是个二元一次方程，包含两个自变量x，一个因变量y，表达了这三个变量之间的关系。</p><ul><li>对数和对数方程式，例如: [latex]y = ln<a href=/latex>1+ e^z</a></li></ul><p>如果 [latex]b^y = x[/latex] 那么 [latex]log_b(x) = y[/latex]，是不是很好理解。[latex]log_e(x) = ln<a href=/latex>x</a>， ln是一种简写形式。</p><ul><li>S 型函数又叫sigmod函数，在神经网络中作为激活函数。</li></ul><p>Sigmoid函数又分为Log-Sigmoid函数和Tan-Sigmoid函数。</p><p>Log-Sigmoid函数: [latex]\sigma(z) = \frac{1}{1+e^{-z}}[/latex]，图形如下：</p><p><img class="img-fluid lazyload blur-up" src=/images/posts/img_5bf6bd51e6f81.webp></p><p>Tan-Sigmoid函数: [latex]\sigma(z) = \frac{2}{1+e^{-2z}} - 1[/latex]</p><h2 id=线性代数>线性代数 <a href=#%e7%ba%bf%e6%80%a7%e4%bb%a3%e6%95%b0 class=anchor aria-hidden=true>#</a></h2><h3 id=张量和张量阶数>张量和张量阶数 <a href=#%e5%bc%a0%e9%87%8f%e5%92%8c%e5%bc%a0%e9%87%8f%e9%98%b6%e6%95%b0 class=anchor aria-hidden=true>#</a></h3><p>现代的数学观点定义：<strong>张量是多重线性函数</strong>，<img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-20-32-48.png>
输入r个向量，输出1个数，r称作张量的阶数。多重线性是指张量对于每个参数都是线性的,对于单个参数就是：
<img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-20-32-23.png></p><p>,其中u,v 是任意向量，c 是任意数。</p><p>TensorFlow用张量这种数据结构来表示所有的数据.你可以把一个张量想象成一个n维的数组或列表.一个张量有一个静态类型和动态类型的维数.张量可以在图中的节点之间流通.在TensorFlow系统中，张量的维数来被描述为阶.但是张量的阶和矩阵的阶并不是同一个概念.张量的阶（有时是关于如顺序或度数或者是n维）是张量维数的一个数量描述.比如，下面的张量（使用Python中list定义的）就是2阶.</p><pre><code>t = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
</code></pre><p>你可以认为一个二阶张量就是<a href=https://www.w3cdoc.com>我们</a>平常所说的矩阵，一阶张量可以认为是一个向量.对于一个二阶张量你可以用语句t[i, j]来访问其中的任何元素.而对于三阶张量你可以用’t[i, j, k]’来访问其中的任何元素.</p><p>张量是所有深度学习框架中最核心的组件，因为后续的所有运算和优化算法都是基于张量进行的。几何代数中定义的张量是基于向量和矩阵的推广，通俗一点理解的话，<a href=https://www.w3cdoc.com>我们</a>可以将标量视为零阶张量，矢量视为一阶张量，那么矩阵就是二阶张量。</p><p>阶,数学实例,Python例子<br>0,纯量 (只有大小), s = 483<br>1,向量(大小和方向), v = [1.1, 2.2, 3.3]<br>2,矩阵(数据表), m = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]<br>3,3阶张量 (数据立体),t = [[[2], [4], [6]], [[8], [10], [12]], [[14], [16], [18]]]<br>n,n阶 (自己想想看)</p><p>举例来说，<a href=https://www.w3cdoc.com>我们</a>可以将任意一张RGB彩色图片表示成一个三阶张量（三个维度分别是图片的高度、宽度和色彩数据）。如下图所示是一张普通的水果图片，按照RGB三原色表示，其可以拆分为三张红色、绿色和蓝色的灰度图片，如果将这种表示方法用张量的形式写出来，就是图中最下方的那张表格。</p><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-20-34-03.png>
<img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-20-34-21.png></p><p>图中只显示了前5行、320列的数据，每个方格代表一个像素点，其中的数据[1.0, 1.0, 1.0]即为颜色。假设用[1.0, 0, 0]表示红色，[0, 1.0, 0]表示绿色，[0, 0, 1.0]表示蓝色，那么如图所示，前面5行的数据则全是白色。</p><p>将这一定义进行扩展，<a href=https://www.w3cdoc.com>我们</a>也可以用四阶张量表示一个包含多张图片的数据集，其中的四个维度分别是：图片在数据集中的编号，图片高度、宽度，以及色彩数据。</p><h3 id=矩阵乘法>矩阵乘法 <a href=#%e7%9f%a9%e9%98%b5%e4%b9%98%e6%b3%95 class=anchor aria-hidden=true>#</a></h3><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-20-34-35.png></p><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-20-36-04.png></p><p>第一个图给出来常用的矩阵乘积因子对数据做转换。第二个图从行向量和列向量理解矩阵乘法。</p><h2 id=三角学>三角学 <a href=#%e4%b8%89%e8%a7%92%e5%ad%a6 class=anchor aria-hidden=true>#</a></h2><ul><li>[Tanh][9]（作为[激活函数][10]进行讲解，无需提前掌握相关知识）</li></ul><p><a href=https://reference.wolfram.com/language/ref/Tanh.html>Tanh</a> 是双曲正切函数，是三角学中普遍使用的 <a href=https://reference.wolfram.com/language/ref/Tan.html>Tan</a> 圆函数的双曲类比. <a href=https://reference.wolfram.com/language/ref/Tanh.html>Tanh</a>[α] 定义为对应的双曲正弦和双曲余弦函数的比值：</p><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-20-36-55.png></p><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-20-37-05.png></p><p>其中 e 是自然对数 <a href=https://reference.wolfram.com/language/ref/Log.html>Log</a> 的底数。常用的激活函数图形如下：</p><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-20-37-15.png></p><p>上面的图形不是很清楚，<a href=https://www.w3cdoc.com>我们</a>可以自己用python绘制一下：</p><pre><code>import matplotlib.pyplot as plt
import numpy as np
import math

def sigmod(x):
    return 1.0/(1.0+np.exp(-x))

def tanh(x):
    y = np.tanh(x)
    return y

def relu(x):
    y = x.copy()
    y[y&lt;0]=0
    return y

x = np.arange(-50.0,50.0,0.1)
y_relu = relu(x)
y_sigmod = sigmod(x)
y_tanh = tanh(x)

plt.plot(x,y_relu,c='r',label=&quot;Relu&quot;,linestyle='--')
plt.plot(x,y_sigmod,c='g',label=&quot;Sigmod&quot;,linestyle='-.')
plt.plot(x,y_tanh,c='b',label=&quot;Tanh&quot;)
plt.ylim([-1,4])
plt.xlim([-4,4])
plt.legend(loc=2)
plt.savefig('sig_tan_relu.png')
plt.show()
</code></pre><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-20-37-36.png></p><h2 id=统计信息>统计信息 <a href=#%e7%bb%9f%e8%ae%a1%e4%bf%a1%e6%81%af class=anchor aria-hidden=true>#</a></h2><ul><li><a href=https://www.khanacademy.org/math/probability/data-distributions-a1/summarizing-center-distributions/v/mean-median-and-mode>均值、中间值、离群值</a>和<a href=https://wikipedia.org/wiki/Standard_deviation>标准偏差</a></li></ul><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-20-37-46.png></p><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-20-37-55.png></p><ul><li>能够读懂<a href=https://wikipedia.org/wiki/Histogram>直方图</a></li></ul><h2 id=微积分可选适合高级主题>微积分（可选，适合高级主题） <a href=#%e5%be%ae%e7%a7%af%e5%88%86%e5%8f%af%e9%80%89%e9%80%82%e5%90%88%e9%ab%98%e7%ba%a7%e4%b8%bb%e9%a2%98 class=anchor aria-hidden=true>#</a></h2><ul><li><a href=https://wikipedia.org/wiki/Derivative>导数</a>概念（您不必真正计算导数）</li></ul><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-20-38-04.png></p><ul><li><p><a href=https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/gradient-and-directional-derivatives/v/gradient>梯度</a>或斜率</p></li><li><p><a href=https://wikipedia.org/wiki/Partial_derivative>偏导数</a>（与梯度紧密相关）
<img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-20-38-11.png></p></li><li><p><a href=https://wikipedia.org/wiki/Chain_rule>链式法则</a>（带您全面了解用于训练神经网络的<a href="https://developers.google.com/machine-learning/crash-course/backprop-scroll/?hl=zh-cn">反向传播算法</a>）
<img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-20-38-35.png></p></li></ul><p><img class="img-fluid lazyload blur-up" src=/images/posts/2022-12-02-20-38-43.png></p><h2 id=参考资料>参考资料 <a href=#%e5%8f%82%e8%80%83%e8%b5%84%e6%96%99 class=anchor aria-hidden=true>#</a></h2><ul><li>https://www.zhihu.com/question/20695804/answer/64920043</li><li>https://blog.csdn.net/pandamax/article/details/63684633</li><li>https://www.jianshu.com/p/b2c43c7d1b09</li></ul><div class="page-footer-meta d-flex flex-column flex-md-row justify-content-between"></div><div class="docs-navigation d-flex justify-content-between"><a href=/bigdata/analysis/model/%E5%95%86%E4%B8%9A%E6%A8%A1%E5%BC%8F/><div class="card my-1"><div class="card-body py-2">&larr; 商业模式</div></div></a><a class=ms-auto href=/bigdata/compute/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E6%9C%AF%E8%AF%AD%E5%8F%8A%E5%90%AB%E4%B9%89/><div class="card my-1"><div class="card-body py-2">机器学习常用术语及含义 &rarr;</div></div></a></div></main></div></div></div><footer class="footer text-muted"><div class=container-xxl><div class=row><div class="col-lg-8 order-last order-lg-first"><ul class=list-inline><li class=list-inline-item>Copyright © 2022-Present 浙ICP备18052292号-3</li></ul></div><div class="col-lg-8 order-first order-lg-last text-lg-end"><ul class=list-inline></ul></div></div></div></footer><script src=/js/bootstrap.min.1117772738b0b01188ff56b000f75758d3ca75fab55d0d7cf813282148e4840455e1fc0a8f1c2951391282de6e64bed66b885160643382a58f67db6d110e9feb.js integrity="sha512-ERd3JziwsBGI/1awAPdXWNPKdfq1XQ18+BMoIUjkhARV4fwKjxwpUTkSgt5uZL7Wa4hRYGQzgqWPZ9ttEQ6f6w==" crossorigin=anonymous defer></script>
<script src=/js/highlight.min.35e8488ad0bca08539c53f48a94a3c02f90c10ddc1ecba4a7fd7ec827cef556dec98a33813e3681b33a5750eefd53e65ab606d30febc27e411c293f2290f96a5.js integrity="sha512-NehIitC8oIU5xT9IqUo8AvkMEN3B7LpKf9fsgnzvVW3smKM4E+NoGzOldQ7v1T5lq2BtMP68J+QRwpPyKQ+WpQ==" crossorigin=anonymous defer></script>
<script src=/main.min.5874482df6978e314928bf4ce1c634b6464aa5445dd098e344aa61159e2b10139d82662edd47e835a3ea422c24214134f15eded85f28e55774a70f9c4919b2b3.js integrity="sha512-WHRILfaXjjFJKL9M4cY0tkZKpURd0JjjRKphFZ4rEBOdgmYu3UfoNaPqQiwkIUE08V7e2F8o5Vd0pw+cSRmysw==" crossorigin=anonymous defer></script>
<script src=/index.min.4ae26272486ea46c5bb0bed7a0b434a91b05e8182cfb839a405dd4e647b05ce5d76d401a5103d822d3b1589fc56335cd372b712d97085b8d89aebf244b1b5501.js integrity="sha512-SuJickhupGxbsL7XoLQ0qRsF6Bgs+4OaQF3U5kewXOXXbUAaUQPYItOxWJ/FYzXNNytxLZcIW42Jrr8kSxtVAQ==" crossorigin=anonymous defer></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML" async></script>
<script type="text/x-mathjax-config;executed=true">
  window.MathJax.Hub.Config({
      showProcessingMessages: false, //关闭js加载过程信息
      messageStyle: "none", //不显示信息
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
          inlineMath: [["$", "$"], ["\\(", "\\)"]], //行内公式选择符
          displayMath: [["$$", "$$"], ["\\[", "\\]"]], //段内公式选择符
          skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //避开某些标签
      },
      "HTML-CSS": {
          availableFonts: ["STIX", "TeX"], //可选字体
          showMathMenu: false //关闭右击菜单显示
      }
  });
  //下面第三个参数可以不写，默认对整个html内的latex进行翻译
  window.MathJax.Hub.Queue(["Typeset", MathJax.Hub, document.getElementsByClassName("ck-content")]);
</script></body></html>